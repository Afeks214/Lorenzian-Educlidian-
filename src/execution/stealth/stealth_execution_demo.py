"""
Stealth Execution System Demo
============================

Comprehensive demonstration of the stealth execution system capabilities.
Shows how large orders are intelligently fragmented and executed to minimize
market impact while maintaining statistical indistinguishability.

Demo Components:
1. Large order stealth fragmentation
2. Natural pattern generation validation
3. Market impact comparison (naive vs stealth)
4. Statistical indistinguishability tests
5. Real-time performance benchmarks

Key Metrics Demonstrated:
- Fragment generation latency: <1ms
- Market impact reduction: >80%
- Statistical indistinguishability: >95% confidence
- Detection probability: <5%
"""

import torch
import numpy as np
import pandas as pd
import time
import structlog
from typing import Dict, List, Tuple, Any
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Import stealth execution components
from src.execution.agents.execution_timing_agent import (
    ExecutionTimingAgent, 
    MarketMicrostructure,
    ExecutionStrategy
)
from src.execution.stealth.order_fragmentation import (
    AdaptiveFragmentationEngine,
    NaturalPatternGenerator,
    FragmentationStrategy
)
from src.execution.stealth.stealth_validation import (
    StealthExecutionValidator,
    ValidationMetrics
)
from training.imitation_learning_pipeline import (
    TradeRecord,
    MarketFeatures
)

# Configure logging
logger = structlog.get_logger()

# Demo configuration
DEMO_CONFIG = {
    'large_order_sizes': [10000, 25000, 50000, 100000],
    'market_conditions': ['normal', 'volatile', 'illiquid'],
    'urgency_levels': [0.2, 0.5, 0.8],
    'stealth_requirements': [0.6, 0.8, 0.95],
    'demo_duration_minutes': 5
}


class StealthExecutionDemo:
    """Main demo orchestrator for stealth execution system"""
    
    def __init__(self):
        # Initialize core components
        self.execution_agent = ExecutionTimingAgent()
        self.fragmentation_engine = AdaptiveFragmentationEngine()
        self.pattern_generator = NaturalPatternGenerator()
        self.validator = StealthExecutionValidator()
        
        # Demo results storage
        self.demo_results = {
            'fragmentation_plans': [],
            'validation_metrics': [],
            'performance_benchmarks': [],
            'impact_comparisons': []
        }
        
        # Generate synthetic historical data for validation
        self.historical_trades = self._generate_synthetic_historical_data(1000)
        
        logger.info("Stealth execution demo initialized")
    
    def _generate_synthetic_historical_data(self, num_trades: int) -> List[TradeRecord]:
        """Generate synthetic historical trade data for validation"""
        trades = []
        current_time = time.time() - 86400  # Start 24 hours ago
        current_price = 100.0
        
        for i in range(num_trades):
            # Generate realistic trade patterns
            size = max(50, np.random.lognormal(np.log(500), 0.8))
            
            # Price walk
            price_change = np.random.normal(0, 0.001) * current_price
            current_price += price_change
            
            # Timing with clustering
            if i == 0:
                timestamp = current_time
            else:
                # Hawkes-like process for realistic timing
                base_interval = np.random.exponential(5.0)  # 5 second average
                clustering_factor = 0.3 if np.random.random() < 0.2 else 1.0
                interval = base_interval * clustering_factor
                timestamp = current_time + interval
            
            current_time = timestamp
            
            side = 'buy' if np.random.random() < 0.52 else 'sell'  # Slight buy bias
            
            trade = TradeRecord(
                timestamp=timestamp,
                price=current_price,
                size=size,
                side=side,
                venue='DEMO',
                trade_id=f'demo_trade_{i:06d}'
            )
            trades.append(trade)
        
        logger.info(f"Generated {num_trades} synthetic historical trades")
        return trades
    
    def _create_market_scenario(self, condition: str) -> MarketMicrostructure:
        """Create market microstructure for different conditions"""
        base_context = MarketMicrostructure()
        
        if condition == 'normal':
            base_context.bid_ask_spread = 0.01
            base_context.market_depth = 10000.0
            base_context.current_volume = 50000.0
            base_context.volatility_regime = 0.15
            base_context.volume_imbalance = 0.02
            
        elif condition == 'volatile':
            base_context.bid_ask_spread = 0.03
            base_context.market_depth = 8000.0
            base_context.current_volume = 80000.0
            base_context.volatility_regime = 0.35
            base_context.volume_imbalance = 0.08
            
        elif condition == 'illiquid':
            base_context.bid_ask_spread = 0.05
            base_context.market_depth = 3000.0
            base_context.current_volume = 15000.0
            base_context.volatility_regime = 0.25
            base_context.volume_imbalance = 0.12
        
        # Common settings
        base_context.order_book_slope = 0.5
        base_context.volume_velocity = 1.0
        base_context.price_momentum = 0.02
        base_context.tick_activity = 0.8
        base_context.permanent_impact = 0.5
        base_context.temporary_impact = 1.0
        base_context.resilience = 0.7
        base_context.time_to_close = 3600.0
        base_context.intraday_pattern = 0.8
        base_context.urgency_score = 0.5
        
        return base_context
    
    def demo_fragmentation_strategies(self) -> Dict[str, Any]:
        """Demonstrate different fragmentation strategies"""
        print("\n" + "="*80)
        print("STEALTH EXECUTION FRAGMENTATION STRATEGY DEMO")
        print("="*80)
        
        order_size = 50000.0
        market_context = self._create_market_scenario('normal')
        
        # Convert to MarketFeatures
        market_features = MarketFeatures(
            mean_trade_size=1000.0,
            std_trade_size=800.0,
            volatility_regime=market_context.volatility_regime,
            buy_sell_imbalance=market_context.volume_imbalance
        )
        
        strategies_to_test = [
            FragmentationStrategy.UNIFORM,
            FragmentationStrategy.PARETO,
            FragmentationStrategy.ADAPTIVE,
            FragmentationStrategy.STEALTH
        ]
        
        strategy_results = {}
        
        for strategy in strategies_to_test:
            print(f"\nüìä Testing {strategy.value.upper()} strategy...")
            
            start_time = time.perf_counter()
            
            # Force strategy selection
            original_method = self.fragmentation_engine.determine_optimal_strategy
            self.fragmentation_engine.determine_optimal_strategy = lambda *args, **kwargs: strategy
            
            try:
                plan = self.fragmentation_engine.create_fragmentation_plan(
                    parent_order_id=f"demo_{strategy.value}",
                    order_size=order_size,
                    side="buy",
                    market_features=market_features,
                    urgency=0.5,
                    stealth_requirement=0.8
                )
                
                generation_time = (time.perf_counter() - start_time) * 1000
                
                # Analyze plan
                sizes = [order.size for order in plan.child_orders]
                timings = [order.target_time for order in plan.child_orders]
                
                strategy_results[strategy.value] = {
                    'num_fragments': len(plan.child_orders),
                    'avg_fragment_size': np.mean(sizes),
                    'size_std': np.std(sizes),
                    'execution_window': plan.execution_window,
                    'stealth_score': plan.stealth_score,
                    'expected_impact_reduction': plan.expected_impact_reduction,
                    'generation_time_ms': generation_time
                }
                
                print(f"   ‚úÖ Fragments: {len(plan.child_orders)}")
                print(f"   ‚úÖ Avg size: {np.mean(sizes):.0f}")
                print(f"   ‚úÖ Stealth score: {plan.stealth_score:.3f}")
                print(f"   ‚úÖ Impact reduction: {plan.expected_impact_reduction:.1%}")
                print(f"   ‚úÖ Generation time: {generation_time:.2f}ms")
                
                self.demo_results['fragmentation_plans'].append(plan)
                
            except Exception as e:
                print(f"   ‚ùå Strategy failed: {e}")
                strategy_results[strategy.value] = {'error': str(e)}
            finally:
                # Restore original method
                self.fragmentation_engine.determine_optimal_strategy = original_method
        
        return strategy_results
    
    def demo_market_impact_analysis(self) -> Dict[str, Any]:
        """Demonstrate market impact analysis"""
        print("\n" + "="*80)
        print("MARKET IMPACT REDUCTION ANALYSIS")
        print("="*80)
        
        impact_results = {}
        
        for condition in DEMO_CONFIG['market_conditions']:
            print(f"\nüìà Testing in {condition.upper()} market conditions...")
            
            market_context = self._create_market_scenario(condition)
            market_volume = market_context.current_volume
            volatility = market_context.volatility_regime
            
            for order_size in [10000, 25000, 50000]:
                print(f"\n   Order size: {order_size:,}")
                
                # Create stealth plan
                market_features = MarketFeatures(
                    mean_trade_size=1000.0,
                    volatility_regime=volatility
                )
                
                plan = self.fragmentation_engine.create_fragmentation_plan(
                    parent_order_id=f"impact_demo_{condition}_{order_size}",
                    order_size=order_size,
                    side="buy",
                    market_features=market_features,
                    stealth_requirement=0.8
                )
                
                # Calculate impact comparison
                from src.execution.stealth.stealth_validation import MarketImpactAnalyzer
                analyzer = MarketImpactAnalyzer()
                
                impact_analysis = analyzer.analyze_impact_reduction(
                    order_size, plan, market_volume, volatility
                )
                
                key = f"{condition}_{order_size}"
                impact_results[key] = impact_analysis
                
                print(f"      Naive impact: {impact_analysis['naive_impact_bps']:.1f} bps")
                print(f"      Stealth impact: {impact_analysis['stealth_impact_bps']:.1f} bps")
                print(f"      Reduction: {impact_analysis['impact_reduction_pct']:.1%}")
                print(f"      Savings: {impact_analysis['absolute_savings_bps']:.1f} bps")
                
                self.demo_results['impact_comparisons'].append(impact_analysis)
        
        return impact_results
    
    def demo_statistical_validation(self) -> Dict[str, Any]:
        """Demonstrate statistical indistinguishability validation"""
        print("\n" + "="*80)
        print("STATISTICAL INDISTINGUISHABILITY VALIDATION")
        print("="*80)
        
        validation_results = {}
        
        # Create test fragmentation plan
        market_context = self._create_market_scenario('normal')
        market_features = MarketFeatures(
            mean_trade_size=1000.0,
            volatility_regime=market_context.volatility_regime
        )
        
        test_plan = self.fragmentation_engine.create_fragmentation_plan(
            parent_order_id="validation_demo",
            order_size=30000.0,
            side="buy",
            market_features=market_features,
            stealth_requirement=0.9
        )
        
        print(f"\nüîç Validating plan with {test_plan.get_total_fragments()} fragments...")
        
        start_time = time.perf_counter()
        
        # Run comprehensive validation
        metrics = self.validator.validate_fragmentation_plan(
            test_plan,
            self.historical_trades,
            market_context.current_volume,
            market_context.volatility_regime
        )
        
        validation_time = (time.perf_counter() - start_time) * 1000
        
        validation_results = {
            'ks_test_p_value': metrics.ks_test_p_value,
            'indistinguishability_score': metrics.indistinguishability_score,
            'impact_reduction_pct': metrics.impact_reduction_pct,
            'timing_naturalness_score': metrics.timing_naturalness_score,
            'validation_time_ms': validation_time,
            'passes_validation': metrics.passes_validation()
        }
        
        print(f"   ‚úÖ KS test p-value: {metrics.ks_test_p_value:.4f}")
        print(f"   ‚úÖ Indistinguishability score: {metrics.indistinguishability_score:.3f}")
        print(f"   ‚úÖ Impact reduction: {metrics.impact_reduction_pct:.1%}")
        print(f"   ‚úÖ Timing naturalness: {metrics.timing_naturalness_score:.3f}")
        print(f"   ‚úÖ Validation time: {validation_time:.2f}ms")
        print(f"   {'‚úÖ PASSED' if metrics.passes_validation() else '‚ùå FAILED'} validation thresholds")
        
        self.demo_results['validation_metrics'].append(metrics)
        
        return validation_results
    
    def demo_performance_benchmarks(self) -> Dict[str, Any]:
        """Demonstrate performance benchmarks"""
        print("\n" + "="*80)
        print("PERFORMANCE BENCHMARKS")
        print("="*80)
        
        benchmark_results = {}
        
        # Test different order sizes
        print("\n‚ö° Fragment generation performance...")
        
        generation_times = []
        order_sizes = [1000, 5000, 10000, 25000, 50000, 100000]
        
        market_features = MarketFeatures(mean_trade_size=1000.0)
        
        for order_size in order_sizes:
            times = []
            
            # Run multiple iterations for statistical significance
            for _ in range(10):
                start_time = time.perf_counter()
                
                plan = self.fragmentation_engine.create_fragmentation_plan(
                    parent_order_id=f"perf_test_{order_size}",
                    order_size=order_size,
                    side="buy",
                    market_features=market_features
                )
                
                end_time = time.perf_counter()
                times.append((end_time - start_time) * 1000)  # Convert to ms
            
            avg_time = np.mean(times)
            generation_times.append(avg_time)
            
            print(f"   Order size {order_size:6,}: {avg_time:.2f}ms avg, {plan.get_total_fragments():3d} fragments")
        
        benchmark_results['generation_times'] = dict(zip(order_sizes, generation_times))
        
        # Test stealth execution integration
        print("\nüéØ Stealth execution integration performance...")
        
        market_context = self._create_market_scenario('normal')
        
        integration_times = []
        for _ in range(5):
            start_time = time.perf_counter()
            
            # Test should_use_stealth_execution decision
            should_use = self.execution_agent.should_use_stealth_execution(
                order_size=25000.0,
                market_context=market_context,
                urgency_level=0.5
            )
            
            if should_use:
                # Execute stealth order
                plan = self.execution_agent.execute_stealth_order(
                    parent_order_id="integration_test",
                    order_size=25000.0,
                    side="buy",
                    market_context=market_context
                )
            
            end_time = time.perf_counter()
            integration_times.append((end_time - start_time) * 1000)
        
        avg_integration_time = np.mean(integration_times)
        benchmark_results['integration_time_ms'] = avg_integration_time
        
        print(f"   Average integration time: {avg_integration_time:.2f}ms")
        print(f"   Target achieved: {'‚úÖ' if avg_integration_time < 10 else '‚ùå'} (<10ms)")
        
        self.demo_results['performance_benchmarks'].append(benchmark_results)
        
        return benchmark_results
    
    def demo_real_time_execution(self) -> Dict[str, Any]:
        """Demonstrate real-time execution scenario"""
        print("\n" + "="*80)
        print("REAL-TIME EXECUTION SCENARIO")
        print("="*80)
        
        print("\nüöÄ Simulating live trading scenario...")
        
        # Scenario: Large institutional order during market hours
        large_order_size = 75000.0
        market_context = self._create_market_scenario('normal')
        
        print(f"   üìä Large order: {large_order_size:,} shares")
        print(f"   üìà Market depth: {market_context.market_depth:,}")
        print(f"   üìâ Volatility: {market_context.volatility_regime:.1%}")
        
        # Step 1: Decision to use stealth
        start_time = time.perf_counter()
        
        should_stealth = self.execution_agent.should_use_stealth_execution(
            order_size=large_order_size,
            market_context=market_context,
            urgency_level=0.3  # Patient execution
        )
        
        decision_time = (time.perf_counter() - start_time) * 1000000  # microseconds
        
        print(f"\n   ‚ö° Decision time: {decision_time:.0f}Œºs")
        print(f"   üéØ Use stealth: {'YES' if should_stealth else 'NO'}")
        
        if should_stealth:
            # Step 2: Create stealth execution plan
            stealth_start = time.perf_counter()
            
            plan = self.execution_agent.execute_stealth_order(
                parent_order_id="live_demo_order",
                order_size=large_order_size,
                side="buy",
                market_context=market_context,
                stealth_requirement=0.85
            )
            
            planning_time = (time.perf_counter() - stealth_start) * 1000
            
            print(f"\n   ‚ö° Planning time: {planning_time:.2f}ms")
            print(f"   üìä Strategy: {plan.strategy.value.upper()}")
            print(f"   üéØ Fragments: {plan.get_total_fragments()}")
            print(f"   ‚è±Ô∏è  Execution window: {plan.execution_window/60:.1f} minutes")
            print(f"   üõ°Ô∏è  Stealth score: {plan.stealth_score:.3f}")
            print(f"   üìâ Expected impact reduction: {plan.expected_impact_reduction:.1%}")
            
            # Step 3: Simulate first few fragment executions
            print(f"\n   üöÄ First 5 fragment dispatch times:")
            for i, child_order in enumerate(plan.child_orders[:5]):
                delay = child_order.target_time - plan.start_time
                print(f"      Fragment {i+1}: {child_order.size:.0f} shares at T+{delay:.0f}s")
            
            execution_results = {
                'decision_time_us': decision_time,
                'planning_time_ms': planning_time,
                'total_latency_ms': planning_time + (decision_time / 1000),
                'stealth_used': True,
                'plan_details': {
                    'strategy': plan.strategy.value,
                    'fragments': plan.get_total_fragments(),
                    'stealth_score': plan.stealth_score,
                    'impact_reduction': plan.expected_impact_reduction
                }
            }
            
        else:
            execution_results = {
                'decision_time_us': decision_time,
                'stealth_used': False,
                'reason': 'Order size below stealth threshold'
            }
        
        print(f"\n   ‚úÖ Total system latency: {execution_results.get('total_latency_ms', 0):.2f}ms")
        print(f"   üéØ Performance target: {'‚úÖ MET' if execution_results.get('total_latency_ms', 0) < 5 else '‚ö†Ô∏è  EXCEEDED'} (<5ms)")
        
        return execution_results
    
    def run_comprehensive_demo(self) -> Dict[str, Any]:
        """Run complete demonstration suite"""
        print("\nüöÄ STEALTH EXECUTION SYSTEM - COMPREHENSIVE DEMO")
        print("=" * 100)
        print("Demonstrating advanced market impact minimization through intelligent")
        print("noise mimicking and stealth execution algorithms.")
        print("=" * 100)
        
        demo_start_time = time.time()
        
        # Run all demo components
        demo_results = {}
        
        try:
            demo_results['fragmentation_strategies'] = self.demo_fragmentation_strategies()
            demo_results['market_impact_analysis'] = self.demo_market_impact_analysis()
            demo_results['statistical_validation'] = self.demo_statistical_validation()
            demo_results['performance_benchmarks'] = self.demo_performance_benchmarks()
            demo_results['real_time_execution'] = self.demo_real_time_execution()
            
        except Exception as e:
            logger.error("Demo execution failed", error=str(e))
            demo_results['error'] = str(e)
        
        demo_duration = time.time() - demo_start_time
        
        # Final summary
        print("\n" + "="*80)
        print("DEMO SUMMARY")
        print("="*80)
        
        if 'error' not in demo_results:
            print("‚úÖ All demo components completed successfully!")
            
            # Key metrics summary
            frag_results = demo_results.get('fragmentation_strategies', {})
            impact_results = demo_results.get('market_impact_analysis', {})
            validation_results = demo_results.get('statistical_validation', {})
            perf_results = demo_results.get('performance_benchmarks', {})
            rt_results = demo_results.get('real_time_execution', {})
            
            print(f"\nüìä KEY PERFORMANCE METRICS:")
            print(f"   üéØ Best stealth score: {max([r.get('stealth_score', 0) for r in frag_results.values() if isinstance(r, dict)], default=0):.3f}")
            print(f"   üìâ Max impact reduction: {max([r.get('impact_reduction_pct', 0) for r in impact_results.values() if isinstance(r, dict)], default=0):.1%}")
            print(f"   üîç Indistinguishability: {validation_results.get('indistinguishability_score', 0):.3f}")
            print(f"   ‚ö° Fragment generation: {min(perf_results.get('generation_times', {}).values(), default=0):.2f}ms")
            print(f"   üöÄ Real-time latency: {rt_results.get('total_latency_ms', 0):.2f}ms")
            
            print(f"\nüèÜ MISSION OBJECTIVES STATUS:")
            print(f"   ‚úÖ Sub-millisecond decisions: {'ACHIEVED' if rt_results.get('decision_time_us', 1000) < 1000 else 'PARTIAL'}")
            print(f"   ‚úÖ >80% impact reduction: {'ACHIEVED' if max([r.get('impact_reduction_pct', 0) for r in impact_results.values() if isinstance(r, dict)], default=0) > 0.8 else 'PARTIAL'}")
            print(f"   ‚úÖ Statistical stealth: {'ACHIEVED' if validation_results.get('indistinguishability_score', 0) > 0.8 else 'PARTIAL'}")
            print(f"   ‚úÖ Real-time performance: {'ACHIEVED' if rt_results.get('total_latency_ms', 10) < 5 else 'PARTIAL'}")
            
        else:
            print("‚ùå Demo encountered errors - see logs for details")
        
        print(f"\n‚è±Ô∏è  Total demo duration: {demo_duration:.1f} seconds")
        print("\nüéâ Stealth Execution Demo Complete!")
        
        return {
            **demo_results,
            'demo_duration_seconds': demo_duration,
            'demo_timestamp': datetime.now().isoformat()
        }


def main():
    """Main demo entry point"""
    print("Initializing Stealth Execution Demo...")
    
    try:
        demo = StealthExecutionDemo()
        results = demo.run_comprehensive_demo()
        
        # Save results
        output_path = Path("stealth_execution_demo_results.json")
        with open(output_path, 'w') as f:
            import json
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nüìÅ Demo results saved to: {output_path}")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        raise


if __name__ == "__main__":
    main()