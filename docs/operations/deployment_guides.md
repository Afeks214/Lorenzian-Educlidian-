# üöÄ DEPLOYMENT GUIDES
**COMPREHENSIVE DEPLOYMENT PROCEDURES FOR SOLID FOUNDATION**

---

## üìã EXECUTIVE SUMMARY

This comprehensive deployment guide provides detailed procedures for deploying all components of the SOLID FOUNDATION system across different environments. It covers development, staging, and production deployments with complete automation scripts, rollback procedures, and validation steps.

**Document Status**: DEPLOYMENT CRITICAL  
**Last Updated**: July 15, 2025  
**Target Audience**: DevOps, SRE, Development Teams  
**Classification**: OPERATIONAL EXCELLENCE  

---

## üéØ DEPLOYMENT ENVIRONMENTS

### Environment Overview
```yaml
environments:
  development:
    purpose: "Development and testing"
    infrastructure: "Local Docker containers"
    monitoring: "Basic logging"
    resources: "Minimal allocation"
    
  staging:
    purpose: "Pre-production testing"
    infrastructure: "Kubernetes cluster"
    monitoring: "Full monitoring stack"
    resources: "Production-like allocation"
    
  production:
    purpose: "Live trading system"
    infrastructure: "High-availability Kubernetes"
    monitoring: "Complete observability"
    resources: "Full allocation with auto-scaling"
```

### Environment Configuration Matrix
```yaml
configuration_matrix:
  development:
    replicas: 1
    resources:
      cpu: "500m"
      memory: "1Gi"
    persistence: false
    monitoring: basic
    
  staging:
    replicas: 2
    resources:
      cpu: "1000m"
      memory: "2Gi"
    persistence: true
    monitoring: full
    
  production:
    replicas: 3
    resources:
      cpu: "2000m"
      memory: "4Gi"
    persistence: true
    monitoring: comprehensive
```

---

## üèóÔ∏è INFRASTRUCTURE DEPLOYMENT

### 1. KUBERNETES DEPLOYMENT

#### Prerequisites Setup
```bash
#!/bin/bash
# Prerequisites setup script

echo "=== Prerequisites Setup ==="

# 1. Install required tools
echo "1. Installing required tools..."
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

# Install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Install Docker
sudo apt-get update
sudo apt-get install -y docker.io
sudo usermod -aG docker $USER

# 2. Verify installations
echo "2. Verifying installations..."
kubectl version --client
helm version
docker --version

# 3. Configure kubectl
echo "3. Configuring kubectl..."
mkdir -p ~/.kube
# Copy kubeconfig file to ~/.kube/config

# 4. Create namespace
echo "4. Creating namespace..."
kubectl create namespace grandmodel-production || true
kubectl create namespace grandmodel-staging || true
kubectl create namespace grandmodel-development || true

# 5. Install monitoring stack
echo "5. Installing monitoring stack..."
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# Install Prometheus
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --create-namespace \
  --set grafana.adminPassword=admin123

echo "Prerequisites setup completed"
```

#### Kubernetes Manifests
```yaml
# /home/QuantNova/GrandModel/k8s/production/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: grandmodel-production
  labels:
    environment: production
    app: grandmodel

---
# /home/QuantNova/GrandModel/k8s/production/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grandmodel-config
  namespace: grandmodel-production
data:
  environment: "production"
  redis.host: "redis-service"
  redis.port: "6379"
  postgres.host: "postgres-service"
  postgres.port: "5432"
  monitoring.enabled: "true"
  log.level: "INFO"

---
# /home/QuantNova/GrandModel/k8s/production/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: grandmodel-secrets
  namespace: grandmodel-production
type: Opaque
data:
  redis-password: <base64-encoded-password>
  postgres-password: <base64-encoded-password>
  jwt-secret: <base64-encoded-secret>
  vault-token: <base64-encoded-token>

---
# /home/QuantNova/GrandModel/k8s/production/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grandmodel-strategic
  namespace: grandmodel-production
  labels:
    app: grandmodel
    component: strategic
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grandmodel
      component: strategic
  template:
    metadata:
      labels:
        app: grandmodel
        component: strategic
    spec:
      containers:
      - name: strategic
        image: grandmodel:latest
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          valueFrom:
            configMapKeyRef:
              name: grandmodel-config
              key: environment
        - name: REDIS_HOST
          valueFrom:
            configMapKeyRef:
              name: grandmodel-config
              key: redis.host
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: grandmodel-secrets
              key: redis-password
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: logs-volume
          mountPath: /app/logs
      volumes:
      - name: config-volume
        configMap:
          name: grandmodel-config
      - name: logs-volume
        emptyDir: {}

---
# /home/QuantNova/GrandModel/k8s/production/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: grandmodel-strategic-service
  namespace: grandmodel-production
  labels:
    app: grandmodel
    component: strategic
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8000
    protocol: TCP
  selector:
    app: grandmodel
    component: strategic

---
# /home/QuantNova/GrandModel/k8s/production/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: grandmodel-strategic-hpa
  namespace: grandmodel-production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: grandmodel-strategic
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### Deployment Script
```bash
#!/bin/bash
# Kubernetes deployment script

set -e

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"
IMAGE_TAG=${2:-latest}

echo "=== Kubernetes Deployment to ${ENVIRONMENT} ==="

# 1. Pre-deployment validation
echo "1. Pre-deployment validation..."
kubectl cluster-info
kubectl get nodes
kubectl get namespace ${NAMESPACE} || kubectl create namespace ${NAMESPACE}

# 2. Build and push Docker image
echo "2. Building and pushing Docker image..."
docker build -t grandmodel:${IMAGE_TAG} .
docker tag grandmodel:${IMAGE_TAG} your-registry/grandmodel:${IMAGE_TAG}
docker push your-registry/grandmodel:${IMAGE_TAG}

# 3. Apply configuration
echo "3. Applying Kubernetes configuration..."
kubectl apply -f k8s/${ENVIRONMENT}/namespace.yaml
kubectl apply -f k8s/${ENVIRONMENT}/configmap.yaml
kubectl apply -f k8s/${ENVIRONMENT}/secret.yaml
kubectl apply -f k8s/${ENVIRONMENT}/storage.yaml

# 4. Deploy applications
echo "4. Deploying applications..."
kubectl apply -f k8s/${ENVIRONMENT}/deployment.yaml
kubectl apply -f k8s/${ENVIRONMENT}/service.yaml
kubectl apply -f k8s/${ENVIRONMENT}/hpa.yaml

# 5. Wait for deployment rollout
echo "5. Waiting for deployment rollout..."
kubectl rollout status deployment/grandmodel-strategic -n ${NAMESPACE}
kubectl rollout status deployment/grandmodel-tactical -n ${NAMESPACE}
kubectl rollout status deployment/grandmodel-risk -n ${NAMESPACE}

# 6. Verify deployment
echo "6. Verifying deployment..."
kubectl get pods -n ${NAMESPACE}
kubectl get services -n ${NAMESPACE}
kubectl get hpa -n ${NAMESPACE}

# 7. Run health checks
echo "7. Running health checks..."
python /home/QuantNova/GrandModel/scripts/health_check.py --environment=${ENVIRONMENT}

# 8. Run smoke tests
echo "8. Running smoke tests..."
python /home/QuantNova/GrandModel/tests/integration/test_end_to_end_pipeline.py --environment=${ENVIRONMENT}

echo "Deployment to ${ENVIRONMENT} completed successfully"
```

### 2. DOCKER DEPLOYMENT

#### Docker Compose for Development
```yaml
# /home/QuantNova/GrandModel/docker-compose.development.yml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --requirepass devpassword
    
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: grandmodel_dev
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: devpassword
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/db/init.sql:/docker-entrypoint-initdb.d/init.sql
    
  grandmodel-strategic:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - redis
      - postgres
    environment:
      - ENVIRONMENT=development
      - REDIS_HOST=redis
      - REDIS_PASSWORD=devpassword
      - POSTGRES_HOST=postgres
      - POSTGRES_PASSWORD=devpassword
    ports:
      - "8000:8000"
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./logs:/app/logs
    command: python -m src.main --component=strategic
    
  grandmodel-tactical:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - redis
      - postgres
    environment:
      - ENVIRONMENT=development
      - REDIS_HOST=redis
      - REDIS_PASSWORD=devpassword
      - POSTGRES_HOST=postgres
      - POSTGRES_PASSWORD=devpassword
    ports:
      - "8001:8000"
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./logs:/app/logs
    command: python -m src.main --component=tactical
    
  grandmodel-risk:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - redis
      - postgres
    environment:
      - ENVIRONMENT=development
      - REDIS_HOST=redis
      - REDIS_PASSWORD=devpassword
      - POSTGRES_HOST=postgres
      - POSTGRES_PASSWORD=devpassword
    ports:
      - "8002:8000"
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./logs:/app/logs
    command: python -m src.main --component=risk

volumes:
  redis_data:
  postgres_data:
```

#### Docker Compose for Production
```yaml
# /home/QuantNova/GrandModel/docker-compose.production.yml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    restart: unless-stopped
    volumes:
      - redis_data:/data
      - ./configs/redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_DB: grandmodel_prod
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_password
    secrets:
      - postgres_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./configs/database/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./scripts/db/init.sql:/docker-entrypoint-initdb.d/init.sql
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    
  grandmodel-strategic:
    image: grandmodel:latest
    restart: unless-stopped
    depends_on:
      - redis
      - postgres
    environment:
      - ENVIRONMENT=production
      - REDIS_HOST=redis
      - POSTGRES_HOST=postgres
    secrets:
      - redis_password
      - postgres_password
      - jwt_secret
    ports:
      - "8000:8000"
    volumes:
      - ./configs:/app/configs:ro
      - ./logs:/app/logs
    command: python -m src.main --component=strategic
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

secrets:
  postgres_password:
    external: true
  redis_password:
    external: true
  jwt_secret:
    external: true

volumes:
  redis_data:
  postgres_data:
```

#### Docker Deployment Script
```bash
#!/bin/bash
# Docker deployment script

set -e

ENVIRONMENT=${1:-development}
COMPOSE_FILE="docker-compose.${ENVIRONMENT}.yml"

echo "=== Docker Deployment for ${ENVIRONMENT} ==="

# 1. Pre-deployment checks
echo "1. Pre-deployment checks..."
if [ ! -f "$COMPOSE_FILE" ]; then
    echo "Error: Compose file $COMPOSE_FILE not found"
    exit 1
fi

docker --version
docker-compose --version

# 2. Build images
echo "2. Building Docker images..."
docker-compose -f $COMPOSE_FILE build

# 3. Create secrets (for production)
if [ "$ENVIRONMENT" = "production" ]; then
    echo "3. Creating secrets..."
    echo "$POSTGRES_PASSWORD" | docker secret create postgres_password -
    echo "$REDIS_PASSWORD" | docker secret create redis_password -
    echo "$JWT_SECRET" | docker secret create jwt_secret -
fi

# 4. Deploy services
echo "4. Deploying services..."
docker-compose -f $COMPOSE_FILE up -d

# 5. Wait for services to be ready
echo "5. Waiting for services to be ready..."
sleep 30

# 6. Verify deployment
echo "6. Verifying deployment..."
docker-compose -f $COMPOSE_FILE ps
docker-compose -f $COMPOSE_FILE logs --tail=50

# 7. Run health checks
echo "7. Running health checks..."
for service in strategic tactical risk; do
    port=$((8000 + $(echo $service | wc -c) % 3))
    curl -f "http://localhost:$port/health" || echo "Health check failed for $service"
done

# 8. Run smoke tests
echo "8. Running smoke tests..."
python /home/QuantNova/GrandModel/tests/integration/test_end_to_end_pipeline.py --environment=$ENVIRONMENT

echo "Docker deployment for $ENVIRONMENT completed"
```

---

## üîß APPLICATION DEPLOYMENT

### 1. STRATEGIC MARL DEPLOYMENT

#### Strategic Component Deployment
```bash
#!/bin/bash
# Strategic MARL component deployment

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"

echo "=== Strategic MARL Deployment ==="

# 1. Deploy strategic models
echo "1. Deploying strategic models..."
kubectl create configmap strategic-models \
  --from-file=models/strategic/ \
  --namespace=${NAMESPACE}

# 2. Deploy strategic configuration
echo "2. Deploying strategic configuration..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: strategic-config
  namespace: ${NAMESPACE}
data:
  strategic_config.yaml: |
    model:
      type: "strategic_marl"
      update_interval: 1800  # 30 minutes
      agents:
        - name: "mlmi_agent"
          enabled: true
          weight: 0.4
        - name: "nwrqk_agent"
          enabled: true
          weight: 0.3
        - name: "regime_detection_agent"
          enabled: true
          weight: 0.3
    
    performance:
      max_latency_ms: 50
      batch_size: 32
      jit_compilation: true
      
    risk:
      max_position_size: 0.1
      stop_loss: 0.02
      take_profit: 0.04
EOF

# 3. Deploy strategic service
echo "3. Deploying strategic service..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grandmodel-strategic
  namespace: ${NAMESPACE}
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grandmodel
      component: strategic
  template:
    metadata:
      labels:
        app: grandmodel
        component: strategic
    spec:
      containers:
      - name: strategic
        image: grandmodel:latest
        ports:
        - containerPort: 8000
        env:
        - name: COMPONENT
          value: "strategic"
        - name: CONFIG_PATH
          value: "/app/config/strategic_config.yaml"
        volumeMounts:
        - name: strategic-config
          mountPath: /app/config
        - name: strategic-models
          mountPath: /app/models
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
      volumes:
      - name: strategic-config
        configMap:
          name: strategic-config
      - name: strategic-models
        configMap:
          name: strategic-models
EOF

# 4. Verify deployment
echo "4. Verifying strategic deployment..."
kubectl rollout status deployment/grandmodel-strategic -n ${NAMESPACE}
kubectl get pods -l component=strategic -n ${NAMESPACE}

echo "Strategic MARL deployment completed"
```

### 2. TACTICAL MARL DEPLOYMENT

#### Tactical Component Deployment
```bash
#!/bin/bash
# Tactical MARL component deployment

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"

echo "=== Tactical MARL Deployment ==="

# 1. Deploy tactical models
echo "1. Deploying tactical models..."
kubectl create configmap tactical-models \
  --from-file=models/tactical/ \
  --namespace=${NAMESPACE}

# 2. Deploy tactical configuration
echo "2. Deploying tactical configuration..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: tactical-config
  namespace: ${NAMESPACE}
data:
  tactical_config.yaml: |
    model:
      type: "tactical_marl"
      update_interval: 300  # 5 minutes
      agents:
        - name: "fvg_agent"
          enabled: true
          weight: 0.25
        - name: "lvn_agent"
          enabled: true
          weight: 0.25
        - name: "mmd_agent"
          enabled: true
          weight: 0.25
        - name: "momentum_agent"
          enabled: true
          weight: 0.25
    
    performance:
      max_latency_ms: 5
      batch_size: 64
      jit_compilation: true
      memory_optimization: true
      
    risk:
      max_position_size: 0.05
      stop_loss: 0.01
      take_profit: 0.02
EOF

# 3. Deploy tactical service with high availability
echo "3. Deploying tactical service..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grandmodel-tactical
  namespace: ${NAMESPACE}
spec:
  replicas: 5
  selector:
    matchLabels:
      app: grandmodel
      component: tactical
  template:
    metadata:
      labels:
        app: grandmodel
        component: tactical
    spec:
      containers:
      - name: tactical
        image: grandmodel:latest
        ports:
        - containerPort: 8000
        env:
        - name: COMPONENT
          value: "tactical"
        - name: CONFIG_PATH
          value: "/app/config/tactical_config.yaml"
        volumeMounts:
        - name: tactical-config
          mountPath: /app/config
        - name: tactical-models
          mountPath: /app/models
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: tactical-config
        configMap:
          name: tactical-config
      - name: tactical-models
        configMap:
          name: tactical-models
EOF

# 4. Deploy HPA for tactical component
echo "4. Deploying HPA for tactical component..."
kubectl apply -f - <<EOF
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: grandmodel-tactical-hpa
  namespace: ${NAMESPACE}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: grandmodel-tactical
  minReplicas: 5
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70
EOF

# 5. Verify deployment
echo "5. Verifying tactical deployment..."
kubectl rollout status deployment/grandmodel-tactical -n ${NAMESPACE}
kubectl get pods -l component=tactical -n ${NAMESPACE}
kubectl get hpa -l component=tactical -n ${NAMESPACE}

echo "Tactical MARL deployment completed"
```

### 3. RISK MANAGEMENT DEPLOYMENT

#### Risk Component Deployment
```bash
#!/bin/bash
# Risk Management component deployment

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"

echo "=== Risk Management Deployment ==="

# 1. Deploy risk models
echo "1. Deploying risk models..."
kubectl create configmap risk-models \
  --from-file=models/risk/ \
  --namespace=${NAMESPACE}

# 2. Deploy risk configuration
echo "2. Deploying risk configuration..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: risk-config
  namespace: ${NAMESPACE}
data:
  risk_config.yaml: |
    risk_management:
      var_calculation:
        method: "monte_carlo"
        confidence_level: 0.95
        time_horizon: 1
        simulations: 10000
        
      position_sizing:
        kelly_criterion: true
        max_position_size: 0.1
        diversification_factor: 0.8
        
      correlation_tracking:
        ewma_lambda: 0.94
        shock_threshold: 0.5
        monitoring_window: 600  # 10 minutes
        
      emergency_protocols:
        max_drawdown: 0.05
        volatility_threshold: 0.3
        correlation_spike_action: "reduce_leverage"
        
    performance:
      max_latency_ms: 10
      calculation_frequency: 60  # 1 minute
      real_time_monitoring: true
EOF

# 3. Deploy risk service with critical availability
echo "3. Deploying risk service..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grandmodel-risk
  namespace: ${NAMESPACE}
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grandmodel
      component: risk
  template:
    metadata:
      labels:
        app: grandmodel
        component: risk
    spec:
      containers:
      - name: risk
        image: grandmodel:latest
        ports:
        - containerPort: 8000
        env:
        - name: COMPONENT
          value: "risk"
        - name: CONFIG_PATH
          value: "/app/config/risk_config.yaml"
        volumeMounts:
        - name: risk-config
          mountPath: /app/config
        - name: risk-models
          mountPath: /app/models
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 3
      volumes:
      - name: risk-config
        configMap:
          name: risk-config
      - name: risk-models
        configMap:
          name: risk-models
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: component
                operator: In
                values: ["risk"]
            topologyKey: "kubernetes.io/hostname"
EOF

# 4. Deploy risk monitoring service
echo "4. Deploying risk monitoring service..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: grandmodel-risk-service
  namespace: ${NAMESPACE}
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8000
    protocol: TCP
  selector:
    app: grandmodel
    component: risk
EOF

# 5. Verify deployment
echo "5. Verifying risk deployment..."
kubectl rollout status deployment/grandmodel-risk -n ${NAMESPACE}
kubectl get pods -l component=risk -n ${NAMESPACE}
kubectl get service grandmodel-risk-service -n ${NAMESPACE}

echo "Risk Management deployment completed"
```

---

## üöÄ DATABASE DEPLOYMENT

### 1. POSTGRESQL DEPLOYMENT

#### PostgreSQL High-Availability Setup
```bash
#!/bin/bash
# PostgreSQL high-availability deployment

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"

echo "=== PostgreSQL High-Availability Deployment ==="

# 1. Create PostgreSQL configuration
echo "1. Creating PostgreSQL configuration..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: ${NAMESPACE}
data:
  postgresql.conf: |
    # Connection settings
    listen_addresses = '*'
    port = 5432
    max_connections = 200
    
    # Memory settings
    shared_buffers = 4GB
    effective_cache_size = 12GB
    work_mem = 256MB
    maintenance_work_mem = 2GB
    
    # Checkpoint settings
    checkpoint_timeout = 15min
    checkpoint_completion_target = 0.9
    
    # WAL settings
    wal_buffers = 16MB
    wal_writer_delay = 200ms
    
    # Logging settings
    log_min_duration_statement = 1000
    log_checkpoints = on
    log_connections = on
    log_disconnections = on
    
    # Replication settings
    wal_level = replica
    max_wal_senders = 10
    max_replication_slots = 10
    
  pg_hba.conf: |
    # TYPE  DATABASE        USER            ADDRESS                 METHOD
    local   all             all                                     trust
    host    all             all             127.0.0.1/32            md5
    host    all             all             ::1/128                 md5
    host    all             all             0.0.0.0/0               md5
    host    replication     all             0.0.0.0/0               md5
EOF

# 2. Deploy PostgreSQL primary
echo "2. Deploying PostgreSQL primary..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-primary
  namespace: ${NAMESPACE}
spec:
  serviceName: postgres-primary
  replicas: 1
  selector:
    matchLabels:
      app: postgres
      role: primary
  template:
    metadata:
      labels:
        app: postgres
        role: primary
    spec:
      containers:
      - name: postgres
        image: postgres:15
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "grandmodel"
        - name: POSTGRES_USER
          value: "postgres"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: POSTGRES_REPLICATION_USER
          value: "replicator"
        - name: POSTGRES_REPLICATION_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: replication-password
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql
        resources:
          requests:
            cpu: 2000m
            memory: 4Gi
          limits:
            cpu: 4000m
            memory: 8Gi
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U postgres
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: postgres-config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
EOF

# 3. Deploy PostgreSQL replica
echo "3. Deploying PostgreSQL replica..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-replica
  namespace: ${NAMESPACE}
spec:
  serviceName: postgres-replica
  replicas: 2
  selector:
    matchLabels:
      app: postgres
      role: replica
  template:
    metadata:
      labels:
        app: postgres
        role: replica
    spec:
      containers:
      - name: postgres
        image: postgres:15
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "grandmodel"
        - name: POSTGRES_USER
          value: "postgres"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        - name: POSTGRES_MASTER_SERVICE
          value: "postgres-primary"
        - name: POSTGRES_REPLICATION_USER
          value: "replicator"
        - name: POSTGRES_REPLICATION_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: replication-password
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        - name: postgres-config
          mountPath: /etc/postgresql
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        command:
        - /bin/bash
        - -c
        - |
          # Initialize replica from primary
          pg_basebackup -h postgres-primary -D /var/lib/postgresql/data -U replicator -v -P -W
          echo "standby_mode = 'on'" >> /var/lib/postgresql/data/recovery.conf
          echo "primary_conninfo = 'host=postgres-primary port=5432 user=replicator'" >> /var/lib/postgresql/data/recovery.conf
          postgres
      volumes:
      - name: postgres-config
        configMap:
          name: postgres-config
  volumeClaimTemplates:
  - metadata:
      name: postgres-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
EOF

# 4. Deploy PostgreSQL services
echo "4. Deploying PostgreSQL services..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: postgres-primary
  namespace: ${NAMESPACE}
spec:
  type: ClusterIP
  ports:
  - port: 5432
    targetPort: 5432
  selector:
    app: postgres
    role: primary
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-replica
  namespace: ${NAMESPACE}
spec:
  type: ClusterIP
  ports:
  - port: 5432
    targetPort: 5432
  selector:
    app: postgres
    role: replica
EOF

# 5. Initialize database
echo "5. Initializing database..."
kubectl wait --for=condition=ready pod -l app=postgres,role=primary -n ${NAMESPACE} --timeout=300s
kubectl exec -it postgres-primary-0 -n ${NAMESPACE} -- psql -U postgres -d grandmodel -f /app/scripts/init.sql

# 6. Verify deployment
echo "6. Verifying PostgreSQL deployment..."
kubectl get statefulset -l app=postgres -n ${NAMESPACE}
kubectl get pods -l app=postgres -n ${NAMESPACE}
kubectl get services -l app=postgres -n ${NAMESPACE}

echo "PostgreSQL high-availability deployment completed"
```

### 2. REDIS DEPLOYMENT

#### Redis Cluster Setup
```bash
#!/bin/bash
# Redis cluster deployment

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"

echo "=== Redis Cluster Deployment ==="

# 1. Create Redis configuration
echo "1. Creating Redis configuration..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: ${NAMESPACE}
data:
  redis.conf: |
    # Network settings
    bind 0.0.0.0
    port 6379
    tcp-backlog 511
    timeout 0
    tcp-keepalive 300
    
    # Memory settings
    maxmemory 2gb
    maxmemory-policy allkeys-lru
    maxmemory-samples 5
    
    # Persistence settings
    save 900 1
    save 300 10
    save 60 10000
    stop-writes-on-bgsave-error yes
    rdbcompression yes
    rdbchecksum yes
    
    # AOF settings
    appendonly yes
    appendfilename "appendonly.aof"
    appendfsync everysec
    no-appendfsync-on-rewrite no
    auto-aof-rewrite-percentage 100
    auto-aof-rewrite-min-size 64mb
    
    # Cluster settings
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
    cluster-announce-ip ${POD_IP}
    cluster-announce-port 6379
    cluster-announce-bus-port 16379
    
    # Client settings
    maxclients 10000
    
    # Slow log settings
    slowlog-log-slower-than 10000
    slowlog-max-len 128
EOF

# 2. Deploy Redis cluster
echo "2. Deploying Redis cluster..."
kubectl apply -f - <<EOF
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
  namespace: ${NAMESPACE}
spec:
  serviceName: redis-cluster
  replicas: 6
  selector:
    matchLabels:
      app: redis
      role: cluster
  template:
    metadata:
      labels:
        app: redis
        role: cluster
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
          name: client
        - containerPort: 16379
          name: gossip
        env:
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        command:
        - redis-server
        - /etc/redis/redis.conf
        volumeMounts:
        - name: redis-config
          mountPath: /etc/redis
        - name: redis-data
          mountPath: /data
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
EOF

# 3. Deploy Redis service
echo "3. Deploying Redis service..."
kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: redis-cluster
  namespace: ${NAMESPACE}
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - port: 6379
    targetPort: 6379
    name: client
  - port: 16379
    targetPort: 16379
    name: gossip
  selector:
    app: redis
    role: cluster
---
apiVersion: v1
kind: Service
metadata:
  name: redis-service
  namespace: ${NAMESPACE}
spec:
  type: ClusterIP
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: cluster
EOF

# 4. Initialize Redis cluster
echo "4. Initializing Redis cluster..."
kubectl wait --for=condition=ready pod -l app=redis -n ${NAMESPACE} --timeout=300s

# Get pod IPs
REDIS_PODS=$(kubectl get pods -l app=redis -n ${NAMESPACE} -o jsonpath='{.items[*].status.podIP}')
REDIS_CLUSTER_IPS=""
for ip in $REDIS_PODS; do
    REDIS_CLUSTER_IPS="$REDIS_CLUSTER_IPS $ip:6379"
done

# Create cluster
kubectl exec -it redis-cluster-0 -n ${NAMESPACE} -- redis-cli --cluster create $REDIS_CLUSTER_IPS --cluster-replicas 1 --cluster-yes

# 5. Verify deployment
echo "5. Verifying Redis deployment..."
kubectl get statefulset redis-cluster -n ${NAMESPACE}
kubectl get pods -l app=redis -n ${NAMESPACE}
kubectl get services -l app=redis -n ${NAMESPACE}

# Test cluster
kubectl exec -it redis-cluster-0 -n ${NAMESPACE} -- redis-cli cluster info

echo "Redis cluster deployment completed"
```

---

## üîÑ ROLLBACK PROCEDURES

### 1. AUTOMATED ROLLBACK

#### Rollback Script
```bash
#!/bin/bash
# Automated rollback script

set -e

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"
COMPONENT=${2:-all}

echo "=== Automated Rollback for ${ENVIRONMENT} ==="

# 1. Check current deployment status
echo "1. Checking current deployment status..."
kubectl get deployments -n ${NAMESPACE}
kubectl get pods -n ${NAMESPACE}

# 2. Rollback specific component or all
if [ "$COMPONENT" = "all" ]; then
    echo "2. Rolling back all components..."
    kubectl rollout undo deployment/grandmodel-strategic -n ${NAMESPACE}
    kubectl rollout undo deployment/grandmodel-tactical -n ${NAMESPACE}
    kubectl rollout undo deployment/grandmodel-risk -n ${NAMESPACE}
else
    echo "2. Rolling back component: $COMPONENT"
    kubectl rollout undo deployment/grandmodel-${COMPONENT} -n ${NAMESPACE}
fi

# 3. Wait for rollback completion
echo "3. Waiting for rollback completion..."
if [ "$COMPONENT" = "all" ]; then
    kubectl rollout status deployment/grandmodel-strategic -n ${NAMESPACE}
    kubectl rollout status deployment/grandmodel-tactical -n ${NAMESPACE}
    kubectl rollout status deployment/grandmodel-risk -n ${NAMESPACE}
else
    kubectl rollout status deployment/grandmodel-${COMPONENT} -n ${NAMESPACE}
fi

# 4. Verify rollback
echo "4. Verifying rollback..."
kubectl get pods -n ${NAMESPACE}
kubectl get deployments -n ${NAMESPACE}

# 5. Run health checks
echo "5. Running health checks..."
python /home/QuantNova/GrandModel/scripts/health_check.py --environment=${ENVIRONMENT}

# 6. Run smoke tests
echo "6. Running smoke tests..."
python /home/QuantNova/GrandModel/tests/integration/test_end_to_end_pipeline.py --environment=${ENVIRONMENT}

# 7. Notify team
echo "7. Notifying team..."
python /home/QuantNova/GrandModel/src/operations/alert_manager.py --rollback-notification \
    --environment=${ENVIRONMENT} \
    --component=${COMPONENT}

echo "Rollback completed successfully"
```

### 2. BLUE-GREEN DEPLOYMENT

#### Blue-Green Deployment Script
```bash
#!/bin/bash
# Blue-Green deployment script

set -e

ENVIRONMENT=${1:-production}
NAMESPACE="grandmodel-${ENVIRONMENT}"
NEW_VERSION=${2:-latest}
CURRENT_COLOR=${3:-blue}

if [ "$CURRENT_COLOR" = "blue" ]; then
    NEW_COLOR="green"
else
    NEW_COLOR="blue"
fi

echo "=== Blue-Green Deployment ==="
echo "Current: $CURRENT_COLOR"
echo "New: $NEW_COLOR"

# 1. Create new environment
echo "1. Creating new environment ($NEW_COLOR)..."
kubectl create namespace grandmodel-${ENVIRONMENT}-${NEW_COLOR} || true

# 2. Deploy to new environment
echo "2. Deploying to new environment..."
sed "s/grandmodel:latest/grandmodel:${NEW_VERSION}/g" k8s/${ENVIRONMENT}/deployment.yaml | \
sed "s/namespace: ${NAMESPACE}/namespace: ${NAMESPACE}-${NEW_COLOR}/g" | \
kubectl apply -f -

# 3. Wait for new deployment to be ready
echo "3. Waiting for new deployment to be ready..."
kubectl rollout status deployment/grandmodel-strategic -n ${NAMESPACE}-${NEW_COLOR}
kubectl rollout status deployment/grandmodel-tactical -n ${NAMESPACE}-${NEW_COLOR}
kubectl rollout status deployment/grandmodel-risk -n ${NAMESPACE}-${NEW_COLOR}

# 4. Run validation tests
echo "4. Running validation tests..."
python /home/QuantNova/GrandModel/scripts/health_check.py --environment=${ENVIRONMENT}-${NEW_COLOR}
python /home/QuantNova/GrandModel/tests/integration/test_end_to_end_pipeline.py --environment=${ENVIRONMENT}-${NEW_COLOR}

# 5. Switch traffic
echo "5. Switching traffic to new environment..."
kubectl patch service grandmodel-strategic-service -n ${NAMESPACE} -p '{"spec":{"selector":{"version":"'${NEW_COLOR}'"}}}'
kubectl patch service grandmodel-tactical-service -n ${NAMESPACE} -p '{"spec":{"selector":{"version":"'${NEW_COLOR}'"}}}'
kubectl patch service grandmodel-risk-service -n ${NAMESPACE} -p '{"spec":{"selector":{"version":"'${NEW_COLOR}'"}}}'

# 6. Monitor new environment
echo "6. Monitoring new environment..."
sleep 300  # Monitor for 5 minutes

# 7. Verify everything is working
echo "7. Final verification..."
python /home/QuantNova/GrandModel/scripts/health_check.py --environment=${ENVIRONMENT}

# 8. Cleanup old environment
echo "8. Cleaning up old environment..."
kubectl delete namespace grandmodel-${ENVIRONMENT}-${CURRENT_COLOR}

echo "Blue-Green deployment completed successfully"
```

---

## üìä DEPLOYMENT VALIDATION

### 1. HEALTH CHECKS

#### Comprehensive Health Check Script
```python
# /home/QuantNova/GrandModel/scripts/deployment_health_check.py
import requests
import time
import logging
import sys
from typing import Dict, List, Tuple

class DeploymentHealthChecker:
    def __init__(self, environment: str):
        self.environment = environment
        self.base_urls = {
            'strategic': f'http://grandmodel-strategic-service.grandmodel-{environment}.svc.cluster.local',
            'tactical': f'http://grandmodel-tactical-service.grandmodel-{environment}.svc.cluster.local',
            'risk': f'http://grandmodel-risk-service.grandmodel-{environment}.svc.cluster.local'
        }
        self.health_checks = []
        self.timeout = 30
    
    def run_all_health_checks(self) -> bool:
        """Run all health checks"""
        print(f"Running health checks for {self.environment} environment...")
        
        all_passed = True
        
        # Component health checks
        for component, url in self.base_urls.items():
            passed = self.check_component_health(component, url)
            all_passed = all_passed and passed
        
        # Database connectivity
        passed = self.check_database_connectivity()
        all_passed = all_passed and passed
        
        # Redis connectivity
        passed = self.check_redis_connectivity()
        all_passed = all_passed and passed
        
        # End-to-end functionality
        passed = self.check_end_to_end_functionality()
        all_passed = all_passed and passed
        
        return all_passed
    
    def check_component_health(self, component: str, base_url: str) -> bool:
        """Check health of individual component"""
        try:
            # Health endpoint
            response = requests.get(f"{base_url}/health", timeout=self.timeout)
            if response.status_code != 200:
                logging.error(f"{component} health check failed: {response.status_code}")
                return False
            
            # Ready endpoint
            response = requests.get(f"{base_url}/ready", timeout=self.timeout)
            if response.status_code != 200:
                logging.error(f"{component} ready check failed: {response.status_code}")
                return False
            
            # Metrics endpoint
            response = requests.get(f"{base_url}/metrics", timeout=self.timeout)
            if response.status_code != 200:
                logging.error(f"{component} metrics check failed: {response.status_code}")
                return False
            
            logging.info(f"{component} health check passed")
            return True
            
        except Exception as e:
            logging.error(f"{component} health check failed: {e}")
            return False
    
    def check_database_connectivity(self) -> bool:
        """Check database connectivity"""
        try:
            import psycopg2
            
            conn = psycopg2.connect(
                host=f"postgres-primary.grandmodel-{self.environment}.svc.cluster.local",
                database="grandmodel",
                user="postgres",
                password="your_password"
            )
            
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            result = cursor.fetchone()
            
            if result[0] == 1:
                logging.info("Database connectivity check passed")
                return True
            else:
                logging.error("Database connectivity check failed")
                return False
                
        except Exception as e:
            logging.error(f"Database connectivity check failed: {e}")
            return False
    
    def check_redis_connectivity(self) -> bool:
        """Check Redis connectivity"""
        try:
            import redis
            
            r = redis.Redis(
                host=f"redis-service.grandmodel-{self.environment}.svc.cluster.local",
                port=6379,
                decode_responses=True
            )
            
            # Test basic operations
            r.set("health_check", "ok")
            result = r.get("health_check")
            r.delete("health_check")
            
            if result == "ok":
                logging.info("Redis connectivity check passed")
                return True
            else:
                logging.error("Redis connectivity check failed")
                return False
                
        except Exception as e:
            logging.error(f"Redis connectivity check failed: {e}")
            return False
    
    def check_end_to_end_functionality(self) -> bool:
        """Check end-to-end functionality"""
        try:
            # Test strategic inference
            response = requests.post(
                f"{self.base_urls['strategic']}/inference",
                json={"test": "data"},
                timeout=self.timeout
            )
            
            if response.status_code != 200:
                logging.error("Strategic inference test failed")
                return False
            
            # Test tactical inference
            response = requests.post(
                f"{self.base_urls['tactical']}/inference",
                json={"test": "data"},
                timeout=self.timeout
            )
            
            if response.status_code != 200:
                logging.error("Tactical inference test failed")
                return False
            
            # Test risk calculation
            response = requests.post(
                f"{self.base_urls['risk']}/calculate",
                json={"test": "data"},
                timeout=self.timeout
            )
            
            if response.status_code != 200:
                logging.error("Risk calculation test failed")
                return False
            
            logging.info("End-to-end functionality check passed")
            return True
            
        except Exception as e:
            logging.error(f"End-to-end functionality check failed: {e}")
            return False

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python deployment_health_check.py <environment>")
        sys.exit(1)
    
    environment = sys.argv[1]
    checker = DeploymentHealthChecker(environment)
    
    if checker.run_all_health_checks():
        print("All health checks passed!")
        sys.exit(0)
    else:
        print("Some health checks failed!")
        sys.exit(1)
```

### 2. SMOKE TESTS

#### Deployment Smoke Test Suite
```python
# /home/QuantNova/GrandModel/tests/deployment/smoke_tests.py
import unittest
import requests
import time
import logging
from typing import Dict, List

class DeploymentSmokeTests(unittest.TestCase):
    def setUp(self):
        self.environment = "production"  # Can be overridden
        self.base_urls = {
            'strategic': f'http://grandmodel-strategic-service.grandmodel-{self.environment}.svc.cluster.local',
            'tactical': f'http://grandmodel-tactical-service.grandmodel-{self.environment}.svc.cluster.local',
            'risk': f'http://grandmodel-risk-service.grandmodel-{self.environment}.svc.cluster.local'
        }
        self.timeout = 30
    
    def test_strategic_component_availability(self):
        """Test strategic component availability"""
        response = requests.get(f"{self.base_urls['strategic']}/health", timeout=self.timeout)
        self.assertEqual(response.status_code, 200)
        
        response = requests.get(f"{self.base_urls['strategic']}/ready", timeout=self.timeout)
        self.assertEqual(response.status_code, 200)
    
    def test_tactical_component_availability(self):
        """Test tactical component availability"""
        response = requests.get(f"{self.base_urls['tactical']}/health", timeout=self.timeout)
        self.assertEqual(response.status_code, 200)
        
        response = requests.get(f"{self.base_urls['tactical']}/ready", timeout=self.timeout)
        self.assertEqual(response.status_code, 200)
    
    def test_risk_component_availability(self):
        """Test risk component availability"""
        response = requests.get(f"{self.base_urls['risk']}/health", timeout=self.timeout)
        self.assertEqual(response.status_code, 200)
        
        response = requests.get(f"{self.base_urls['risk']}/ready", timeout=self.timeout)
        self.assertEqual(response.status_code, 200)
    
    def test_strategic_inference_functionality(self):
        """Test strategic inference functionality"""
        test_data = {
            "market_data": {
                "price": 100.0,
                "volume": 1000,
                "timestamp": int(time.time())
            }
        }
        
        response = requests.post(
            f"{self.base_urls['strategic']}/inference",
            json=test_data,
            timeout=self.timeout
        )
        
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertIn("decision", result)
        self.assertIn("confidence", result)
    
    def test_tactical_inference_functionality(self):
        """Test tactical inference functionality"""
        test_data = {
            "market_data": {
                "price": 100.0,
                "volume": 1000,
                "timestamp": int(time.time())
            }
        }
        
        response = requests.post(
            f"{self.base_urls['tactical']}/inference",
            json=test_data,
            timeout=self.timeout
        )
        
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertIn("decision", result)
        self.assertIn("confidence", result)
    
    def test_risk_calculation_functionality(self):
        """Test risk calculation functionality"""
        test_data = {
            "portfolio": {
                "positions": [
                    {"symbol": "AAPL", "quantity": 100, "price": 150.0},
                    {"symbol": "GOOGL", "quantity": 50, "price": 2500.0}
                ]
            }
        }
        
        response = requests.post(
            f"{self.base_urls['risk']}/calculate",
            json=test_data,
            timeout=self.timeout
        )
        
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertIn("var", result)
        self.assertIn("risk_score", result)
    
    def test_performance_requirements(self):
        """Test performance requirements"""
        # Test strategic inference latency
        start_time = time.time()
        response = requests.post(
            f"{self.base_urls['strategic']}/inference",
            json={"test": "data"},
            timeout=self.timeout
        )
        strategic_latency = (time.time() - start_time) * 1000  # ms
        
        self.assertLess(strategic_latency, 50)  # 50ms requirement
        
        # Test tactical inference latency
        start_time = time.time()
        response = requests.post(
            f"{self.base_urls['tactical']}/inference",
            json={"test": "data"},
            timeout=self.timeout
        )
        tactical_latency = (time.time() - start_time) * 1000  # ms
        
        self.assertLess(tactical_latency, 5)  # 5ms requirement
    
    def test_error_handling(self):
        """Test error handling"""
        # Test invalid input
        response = requests.post(
            f"{self.base_urls['strategic']}/inference",
            json={"invalid": "data"},
            timeout=self.timeout
        )
        
        self.assertEqual(response.status_code, 400)
        
        # Test missing input
        response = requests.post(
            f"{self.base_urls['tactical']}/inference",
            json={},
            timeout=self.timeout
        )
        
        self.assertEqual(response.status_code, 400)

if __name__ == "__main__":
    unittest.main()
```

---

## üìã DEPLOYMENT CHECKLIST

### Pre-Deployment Checklist
```bash
#!/bin/bash
# Pre-deployment checklist

echo "=== Pre-Deployment Checklist ==="

# 1. Code Quality
echo "1. Code Quality Checks..."
python -m pytest tests/ -v --tb=short
python -m flake8 src/ --max-line-length=120
python -m mypy src/ --ignore-missing-imports

# 2. Security Scan
echo "2. Security Scan..."
python /home/QuantNova/GrandModel/src/security/attack_detection.py --pre-deployment-scan
./scripts/security/vulnerability-scan.sh

# 3. Performance Validation
echo "3. Performance Validation..."
python /home/QuantNova/GrandModel/tests/performance/test_comprehensive_performance_benchmarks.py

# 4. Configuration Validation
echo "4. Configuration Validation..."
python /home/QuantNova/GrandModel/scripts/validate_configs.py --all-environments

# 5. Database Migration
echo "5. Database Migration (dry run)..."
python /home/QuantNova/GrandModel/scripts/database/migrate-production.py --dry-run

echo "Pre-deployment checklist completed"
```

### Post-Deployment Checklist
```bash
#!/bin/bash
# Post-deployment checklist

echo "=== Post-Deployment Checklist ==="

# 1. Health Checks
echo "1. Health Checks..."
python /home/QuantNova/GrandModel/scripts/deployment_health_check.py production

# 2. Smoke Tests
echo "2. Smoke Tests..."
python -m pytest /home/QuantNova/GrandModel/tests/deployment/smoke_tests.py -v

# 3. Performance Verification
echo "3. Performance Verification..."
python /home/QuantNova/GrandModel/src/performance/realtime_monitor.py --deployment-validation

# 4. Monitoring Setup
echo "4. Monitoring Setup..."
python /home/QuantNova/GrandModel/src/monitoring/metrics_exporter.py --validate-deployment

# 5. Backup Verification
echo "5. Backup Verification..."
./scripts/database/verify-backups.sh

echo "Post-deployment checklist completed"
```

---

**Document Version**: 1.0  
**Last Updated**: July 15, 2025  
**Next Review**: July 22, 2025  
**Owner**: DevOps Team  
**Classification**: DEPLOYMENT CRITICAL