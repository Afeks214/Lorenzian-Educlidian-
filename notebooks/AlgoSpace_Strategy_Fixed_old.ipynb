{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlgoSpace Strategy - Complete Fixed Implementation\n",
    "\n",
    "**Version**: 3.0 (Fixed)\n",
    "**Features**: \n",
    "- Proper synergy pattern detection for all 4 types\n",
    "- Separate backtests for each synergy\n",
    "- Monte Carlo validation per synergy\n",
    "- Fixed vectorbt implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1: Environment Setup and Imports ===\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import vectorbt as vbt\n",
    "import numba\n",
    "from numba import jit, njit, prange\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"=== AlgoSpace Multi-Indicator Trading Strategy ===\")\n",
    "print(\"Version: 3.0 - Complete Fixed Implementation\")\n",
    "print(\"Synergies: Type 1-4 with proper pattern detection\")\n",
    "print(\"\\nEnvironment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === CELL 2: Data Loading Functions ===\n\ndef load_and_standardize_data(file_path):\n    \"\"\"Load and standardize CSV data from a local file path\"\"\"\n    df = pd.read_csv(file_path)\n    \n    # Handle datetime columns - looking for common patterns\n    datetime_cols = ['Timestamp', 'timestamp', 'Date', 'date', 'Time', 'time', 'Datetime', 'datetime']\n    datetime_col = None\n    \n    for col in datetime_cols:\n        if col in df.columns:\n            datetime_col = col\n            break\n    \n    if datetime_col:\n        try:\n            # Try different date formats\n            # First try with dayfirst=True for DD/MM/YYYY format\n            df['Datetime'] = pd.to_datetime(df[datetime_col], dayfirst=True, errors='coerce')\n            \n            # Check if parsing was successful\n            valid_dates = df['Datetime'].notna().sum()\n            \n            if valid_dates < len(df) * 0.8:\n                # Try with dayfirst=False for MM/DD/YYYY format\n                df['Datetime'] = pd.to_datetime(df[datetime_col], dayfirst=False, errors='coerce')\n                valid_dates = df['Datetime'].notna().sum()\n            \n            if valid_dates > len(df) * 0.8:\n                df = df.set_index('Datetime')\n                df = df.sort_index()\n                print(f\"✅ Successfully set datetime index with {valid_dates:,} valid dates\")\n            else:\n                print(f\"⚠️ Datetime conversion had issues, keeping original index\")\n                # Try to create index from row numbers\n                df.index = pd.to_datetime('2020-01-01') + pd.to_timedelta(df.index, unit='5T')\n                print(f\"Created synthetic datetime index\")\n        except Exception as e:\n            print(f\"❌ Could not convert {datetime_col} to datetime: {e}\")\n            # Create synthetic datetime index\n            df.index = pd.to_datetime('2020-01-01') + pd.to_timedelta(df.index, unit='5T')\n            print(f\"Created synthetic datetime index\")\n    else:\n        print(\"⚠️ No datetime column found, creating synthetic datetime index\")\n        df.index = pd.to_datetime('2020-01-01') + pd.to_timedelta(df.index, unit='5T')\n    \n    # Standardize column names\n    standard_columns = {\n        'open': 'Open', 'high': 'High', 'low': 'Low',\n        'close': 'Close', 'volume': 'Volume'\n    }\n    \n    for col in df.columns:\n        col_lower = col.lower()\n        if col_lower in standard_columns:\n            df = df.rename(columns={col: standard_columns[col_lower]})\n    \n    # Ensure numeric columns\n    for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n        if col in df.columns:\n            df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    return df\n\nprint(\"Data loading functions defined!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === CELL 3: Load Data Files ===\n\n# File paths\nfile_path_5min = \"/home/QuantNova/AlgoSpace-Strategy-1/@NQ - 5 min - ETH.csv\"\nfile_path_30min = \"/home/QuantNova/AlgoSpace-Strategy-1/NQ - 30 min - ETH.csv\"\n\n# Load 5-minute data\nprint(\"Loading 5-minute data...\")\ntry:\n    df_5m = load_and_standardize_data(file_path_5min)\n    print(f\"📊 5-minute data shape: {df_5m.shape}\")\n    print(f\"📊 Columns: {list(df_5m.columns)}\")\n    print(f\"📊 Index type: {type(df_5m.index)}\")\n    if isinstance(df_5m.index, pd.DatetimeIndex):\n        print(f\"📊 Date range: {df_5m.index[0]} to {df_5m.index[-1]}\")\nexcept Exception as e:\n    print(f\"❌ Error loading 5-minute data: {str(e)}\")\n    df_5m = pd.DataFrame()\n\n# Load 30-minute data\nprint(\"\\nLoading 30-minute data...\")\ntry:\n    df_30m = load_and_standardize_data(file_path_30min)\n    # For 30-minute data, adjust the synthetic index if needed\n    if 'Timestamp' in df_30m.columns and not isinstance(df_30m.index, pd.DatetimeIndex):\n        df_30m.index = pd.to_datetime('2020-01-01') + pd.to_timedelta(df_30m.index * 6, unit='5T')\n    \n    print(f\"📊 30-minute data shape: {df_30m.shape}\")\n    print(f\"📊 Columns: {list(df_30m.columns)}\")\n    print(f\"📊 Index type: {type(df_30m.index)}\")\n    if isinstance(df_30m.index, pd.DatetimeIndex):\n        print(f\"📊 Date range: {df_30m.index[0]} to {df_30m.index[-1]}\")\nexcept Exception as e:\n    print(f\"❌ Error loading 30-minute data: {str(e)}\")\n    df_30m = pd.DataFrame()\n\nprint(\"\\n✅ Data loading complete!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 4: FVG Detection (Optimized from Reference) ===\n",
    "\n",
    "@njit\n",
    "def generate_fvg_data_fast(high, low, n):\n",
    "    \"\"\"Numba-optimized FVG generation\"\"\"\n",
    "    # Pre-allocate output arrays\n",
    "    bull_fvg_detected = np.zeros(n, dtype=np.bool_)\n",
    "    bear_fvg_detected = np.zeros(n, dtype=np.bool_)\n",
    "    is_bull_fvg_active = np.zeros(n, dtype=np.bool_)\n",
    "    is_bear_fvg_active = np.zeros(n, dtype=np.bool_)\n",
    "    \n",
    "    # Fast FVG detection\n",
    "    for i in range(2, n):\n",
    "        # Bullish FVG: Current low > Previous high\n",
    "        if low[i] > high[i-2]:\n",
    "            bull_fvg_detected[i] = True\n",
    "            \n",
    "            # FVG remains active until invalidated\n",
    "            for j in range(i, min(i+20, n)):\n",
    "                is_bull_fvg_active[j] = True\n",
    "                \n",
    "                # Invalidate if price breaks below\n",
    "                if low[j] < high[i-2]:\n",
    "                    break\n",
    "        \n",
    "        # Bearish FVG: Current high < Previous low\n",
    "        if high[i] < low[i-2]:\n",
    "            bear_fvg_detected[i] = True\n",
    "            \n",
    "            # FVG remains active until invalidated\n",
    "            for j in range(i, min(i+20, n)):\n",
    "                is_bear_fvg_active[j] = True\n",
    "                \n",
    "                # Invalidate if price breaks above\n",
    "                if high[j] > low[i-2]:\n",
    "                    break\n",
    "    \n",
    "    return bull_fvg_detected, bear_fvg_detected, is_bull_fvg_active, is_bear_fvg_active\n",
    "\n",
    "# Calculate FVG for 5-minute data\n",
    "if not df_5m.empty:\n",
    "    print(\"🚀 Calculating FVG on 5-minute data...\")\n",
    "    high_array = df_5m['High'].values\n",
    "    low_array = df_5m['Low'].values\n",
    "    \n",
    "    bull_fvg, bear_fvg, bull_active, bear_active = generate_fvg_data_fast(\n",
    "        high_array, low_array, len(df_5m)\n",
    "    )\n",
    "    \n",
    "    df_5m['FVG_Bull_Detected'] = bull_fvg\n",
    "    df_5m['FVG_Bear_Detected'] = bear_fvg\n",
    "    df_5m['FVG_Bull_Active'] = bull_active\n",
    "    df_5m['FVG_Bear_Active'] = bear_active\n",
    "    \n",
    "    print(f\"✅ FVG Detection Complete:\")\n",
    "    print(f\"  • Bullish FVGs: {bull_fvg.sum():,}\")\n",
    "    print(f\"  • Bearish FVGs: {bear_fvg.sum():,}\")\n",
    "else:\n",
    "    print(\"❌ No 5-minute data for FVG calculation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === CELL 5: MLMI Calculation (Full Implementation from Reference) ===\n\nfrom numba.experimental import jitclass\nfrom scipy.spatial import cKDTree\n\n# Define spec for jitclass\nspec = [\n    ('parameter1', numba.float64[:]),\n    ('parameter2', numba.float64[:]),\n    ('priceArray', numba.float64[:]),\n    ('resultArray', numba.int64[:]),\n    ('size', numba.int64),\n    ('max_size', numba.int64)\n]\n\n@jitclass(spec)\nclass MLMIDataFast:\n    def __init__(self, max_size=10000):\n        self.parameter1 = np.zeros(max_size, dtype=np.float64)\n        self.parameter2 = np.zeros(max_size, dtype=np.float64)\n        self.priceArray = np.zeros(max_size, dtype=np.float64)\n        self.resultArray = np.zeros(max_size, dtype=np.int64)\n        self.size = 0\n        self.max_size = max_size\n    \n    def storePreviousTrade(self, p1, p2, close_price):\n        if self.size >= self.max_size:\n            shift_amount = self.max_size // 4\n            for i in range(shift_amount, self.max_size):\n                self.parameter1[i - shift_amount] = self.parameter1[i]\n                self.parameter2[i - shift_amount] = self.parameter2[i]\n                self.priceArray[i - shift_amount] = self.priceArray[i]\n                self.resultArray[i - shift_amount] = self.resultArray[i]\n            self.size = self.max_size - shift_amount\n        \n        if self.size > 0:\n            result = 1 if close_price >= self.priceArray[self.size-1] else -1\n            self.parameter1[self.size] = p1\n            self.parameter2[self.size] = p2\n            self.priceArray[self.size] = close_price\n            self.resultArray[self.size] = result\n            self.size += 1\n        else:\n            self.parameter1[0] = p1\n            self.parameter2[0] = p2\n            self.priceArray[0] = close_price\n            self.resultArray[0] = 0\n            self.size = 1\n\n@njit(fastmath=True, parallel=True)\ndef wma_numba_fast(series, length):\n    \"\"\"Weighted Moving Average\"\"\"\n    n = len(series)\n    result = np.zeros(n, dtype=np.float64)\n    weights = np.arange(1, length + 1, dtype=np.float64)\n    sum_weights = np.sum(weights)\n    \n    for i in prange(length-1, n):\n        weighted_sum = 0.0\n        for j in range(length):\n            weighted_sum += series[i-j] * weights[length-j-1]\n        result[i] = weighted_sum / sum_weights\n    \n    return result\n\n@njit(fastmath=True)\ndef calculate_rsi_numba_fast(prices, window):\n    \"\"\"RSI calculation\"\"\"\n    n = len(prices)\n    rsi = np.zeros(n, dtype=np.float64)\n    \n    delta = np.zeros(n, dtype=np.float64)\n    gain = np.zeros(n, dtype=np.float64)\n    loss = np.zeros(n, dtype=np.float64)\n    avg_gain = np.zeros(n, dtype=np.float64)\n    avg_loss = np.zeros(n, dtype=np.float64)\n    \n    for i in range(1, n):\n        delta[i] = prices[i] - prices[i-1]\n        if delta[i] > 0:\n            gain[i] = delta[i]\n        else:\n            loss[i] = -delta[i]\n    \n    if window <= n:\n        avg_gain[window-1] = np.sum(gain[:window]) / window\n        avg_loss[window-1] = np.sum(loss[:window]) / window\n        \n        if avg_loss[window-1] == 0:\n            rsi[window-1] = 100\n        else:\n            rs = avg_gain[window-1] / avg_loss[window-1]\n            rsi[window-1] = 100 - (100 / (1 + rs))\n    \n    for i in range(window, n):\n        avg_gain[i] = (avg_gain[i-1] * (window-1) + gain[i]) / window\n        avg_loss[i] = (avg_loss[i-1] * (window-1) + loss[i]) / window\n        \n        if avg_loss[i] == 0:\n            rsi[i] = 100\n        else:\n            rs = avg_gain[i] / avg_loss[i]\n            rsi[i] = 100 - (100 / (1 + rs))\n    \n    return rsi\n\ndef calculate_mlmi_optimized(df, num_neighbors=200, momentum_window=20):\n    \"\"\"Full MLMI calculation from reference\"\"\"\n    print(\"🚀 Calculating MLMI with full implementation...\")\n    \n    close_array = df['Close'].values\n    n = len(close_array)\n    \n    # Calculate indicators\n    ma_quick = wma_numba_fast(close_array, 5)\n    ma_slow = wma_numba_fast(close_array, 20)\n    rsi_quick = calculate_rsi_numba_fast(close_array, 5)\n    rsi_slow = calculate_rsi_numba_fast(close_array, 20)\n    rsi_quick_wma = wma_numba_fast(rsi_quick, momentum_window)\n    rsi_slow_wma = wma_numba_fast(rsi_slow, momentum_window)\n    \n    # Detect crossovers\n    pos = np.zeros(n, dtype=np.bool_)\n    neg = np.zeros(n, dtype=np.bool_)\n    for i in range(1, n):\n        if ma_quick[i] > ma_slow[i] and ma_quick[i-1] <= ma_slow[i-1]:\n            pos[i] = True\n        if ma_quick[i] < ma_slow[i] and ma_quick[i-1] >= ma_slow[i-1]:\n            neg[i] = True\n    \n    # Initialize MLMI data\n    mlmi_data = MLMIDataFast(max_size=min(10000, n))\n    mlmi_values = np.zeros(n, dtype=np.float64)\n    \n    # Process crossovers\n    crossover_indices = np.where(pos | neg)[0]\n    for i in crossover_indices:\n        if not np.isnan(rsi_slow_wma[i]) and not np.isnan(rsi_quick_wma[i]):\n            mlmi_data.storePreviousTrade(\n                rsi_slow_wma[i],\n                rsi_quick_wma[i],\n                close_array[i]\n            )\n    \n    # Generate MLMI predictions using kNN\n    if mlmi_data.size > 0:\n        points = np.column_stack((mlmi_data.parameter1[:mlmi_data.size], \n                                 mlmi_data.parameter2[:mlmi_data.size]))\n        tree = cKDTree(points)\n        \n        for i in range(momentum_window, n):\n            if not np.isnan(rsi_slow_wma[i]) and not np.isnan(rsi_quick_wma[i]):\n                k = min(num_neighbors, mlmi_data.size)\n                distances, indices = tree.query([rsi_slow_wma[i], rsi_quick_wma[i]], k=k)\n                neighbors = mlmi_data.resultArray[indices]\n                mlmi_values[i] = np.sum(neighbors)\n    \n    # Add results to dataframe\n    df['mlmi'] = mlmi_values\n    df['mlmi_ma'] = wma_numba_fast(mlmi_values, 20)\n    df['mlmi_bull'] = mlmi_values > 0\n    df['mlmi_bear'] = mlmi_values < 0\n    \n    # Additional crossovers\n    mlmi_bull_cross = np.zeros(n, dtype=np.bool_)\n    mlmi_bear_cross = np.zeros(n, dtype=np.bool_)\n    for i in range(1, n):\n        if mlmi_values[i] > 0 and mlmi_values[i-1] <= 0:\n            mlmi_bull_cross[i] = True\n        if mlmi_values[i] < 0 and mlmi_values[i-1] >= 0:\n            mlmi_bear_cross[i] = True\n    \n    df['mlmi_bull_cross'] = mlmi_bull_cross\n    df['mlmi_bear_cross'] = mlmi_bear_cross\n    \n    print(f\"✅ MLMI Calculation Complete:\")\n    print(f\"  • MLMI range: {mlmi_values.min():.2f} to {mlmi_values.max():.2f}\")\n    print(f\"  • Bullish crosses: {mlmi_bull_cross.sum():,}\")\n    print(f\"  • Bearish crosses: {mlmi_bear_cross.sum():,}\")\n    \n    return df\n\n# Calculate MLMI for 30-minute data\nif not df_30m.empty:\n    df_30m = calculate_mlmi_optimized(df_30m)\nelse:\n    print(\"❌ No 30-minute data for MLMI calculation\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# === CELL 6: NW-RQK Calculation (Full Implementation from Reference) ===\n\n@njit(numba.float64(numba.float64[:], numba.int64, numba.float64, numba.float64))\ndef kernel_regression_numba(src, size, h_param, r_param):\n    \"\"\"Nadaraya-Watson Regression using Rational Quadratic Kernel\"\"\"\n    current_weight = 0.0\n    cumulative_weight = 0.0\n    \n    for i in range(min(size + 25 + 1, len(src))):\n        if i < len(src):\n            y = src[i]\n            w = (1 + (i**2 / ((h_param**2) * 2 * r_param)))**(-r_param)\n            current_weight += y * w\n            cumulative_weight += w\n    \n    if cumulative_weight == 0:\n        return np.nan\n    \n    return current_weight / cumulative_weight\n\n@njit(parallel=True)\ndef calculate_nw_regression(prices, h_param, h_lag_param, r_param, x_0_param):\n    \"\"\"Calculate Nadaraya-Watson regression for the entire price series\"\"\"\n    n = len(prices)\n    yhat1 = np.full(n, np.nan)\n    yhat2 = np.full(n, np.nan)\n    \n    for i in prange(x_0_param, n):\n        window_size = min(i + 1, n)\n        src = np.zeros(window_size)\n        for j in range(window_size):\n            src[j] = prices[i-j]\n        \n        yhat1[i] = kernel_regression_numba(src, i, h_param, r_param)\n        yhat2[i] = kernel_regression_numba(src, i, h_param-h_lag_param, r_param)\n    \n    return yhat1, yhat2\n\ndef calculate_nw_rqk(df, src_col='Close', h=8.0, r=8.0, x_0=25, lag=2):\n    \"\"\"Full NW-RQK calculation from reference\"\"\"\n    print(\"🚀 Calculating NW-RQK with full implementation...\")\n    \n    prices = df[src_col].values\n    \n    # Calculate regression values\n    yhat1, yhat2 = calculate_nw_regression(prices, h, h-lag, r, x_0)\n    \n    # Add to dataframe\n    df['yhat1'] = yhat1\n    df['yhat2'] = yhat2\n    \n    # Calculate rates of change\n    wasBearish = np.zeros(len(df), dtype=bool)\n    wasBullish = np.zeros(len(df), dtype=bool)\n    isBearish = np.zeros(len(df), dtype=bool)\n    isBullish = np.zeros(len(df), dtype=bool)\n    \n    for i in range(2, len(df)):\n        if not np.isnan(yhat1[i]) and not np.isnan(yhat1[i-1]) and not np.isnan(yhat1[i-2]):\n            wasBearish[i] = yhat1[i-2] > yhat1[i-1]\n            wasBullish[i] = yhat1[i-2] < yhat1[i-1]\n            isBearish[i] = yhat1[i-1] > yhat1[i]\n            isBullish[i] = yhat1[i-1] < yhat1[i]\n    \n    df['wasBearish'] = wasBearish\n    df['wasBullish'] = wasBullish\n    df['isBearish'] = isBearish\n    df['isBullish'] = isBullish\n    \n    # Detect changes\n    isBearishChange = isBearish & wasBullish\n    isBullishChange = isBullish & wasBearish\n    \n    df['isBearishChange'] = isBearishChange\n    df['isBullishChange'] = isBullishChange\n    df['nwrqk_bull'] = isBullishChange\n    df['nwrqk_bear'] = isBearishChange\n    \n    # Calculate crossovers\n    isBullishCross = np.zeros(len(df), dtype=bool)\n    isBearishCross = np.zeros(len(df), dtype=bool)\n    \n    for i in range(1, len(df)):\n        if not np.isnan(yhat1[i]) and not np.isnan(yhat2[i]):\n            if yhat2[i] > yhat1[i] and yhat2[i-1] <= yhat1[i-1]:\n                isBullishCross[i] = True\n            elif yhat2[i] < yhat1[i] and yhat2[i-1] >= yhat1[i-1]:\n                isBearishCross[i] = True\n    \n    df['isBullishCross'] = isBullishCross\n    df['isBearishCross'] = isBearishCross\n    \n    print(f\"✅ NW-RQK Calculation Complete:\")\n    print(f\"  • Bullish changes: {isBullishChange.sum():,}\")\n    print(f\"  • Bearish changes: {isBearishChange.sum():,}\")\n    print(f\"  • Bullish crosses: {isBullishCross.sum():,}\")\n    print(f\"  • Bearish crosses: {isBearishCross.sum():,}\")\n    \n    return df\n\n# Calculate NW-RQK for 30-minute data\nif not df_30m.empty:\n    df_30m = calculate_nw_rqk(df_30m)\nelse:\n    print(\"❌ No 30-minute data for NW-RQK calculation\")"
  },
  {
   "cell_type": "code",
   "source": "# === CELL 6.5: Data Status Check ===\n\nprint(\"=\"*80)\nprint(\"📊 DATA STATUS CHECK\")\nprint(\"=\"*80)\n\n# Check 5-minute data\nprint(\"\\n5-MINUTE DATA:\")\nif not df_5m.empty:\n    print(f\"  ✅ Shape: {df_5m.shape}\")\n    print(f\"  ✅ Index type: {type(df_5m.index)}\")\n    print(f\"  ✅ Has datetime index: {isinstance(df_5m.index, pd.DatetimeIndex)}\")\n    if 'FVG_Bull_Active' in df_5m.columns:\n        print(f\"  ✅ FVG calculated: Bull={df_5m['FVG_Bull_Active'].sum():,}, Bear={df_5m['FVG_Bear_Active'].sum():,}\")\nelse:\n    print(\"  ❌ No data loaded\")\n\n# Check 30-minute data\nprint(\"\\n30-MINUTE DATA:\")\nif not df_30m.empty:\n    print(f\"  ✅ Shape: {df_30m.shape}\")\n    print(f\"  ✅ Index type: {type(df_30m.index)}\")\n    print(f\"  ✅ Has datetime index: {isinstance(df_30m.index, pd.DatetimeIndex)}\")\n    if 'mlmi' in df_30m.columns:\n        print(f\"  ✅ MLMI calculated: range={df_30m['mlmi'].min():.2f} to {df_30m['mlmi'].max():.2f}\")\n    if 'nwrqk_bull' in df_30m.columns:\n        print(f\"  ✅ NW-RQK calculated: Bull={df_30m['nwrqk_bull'].sum():,}, Bear={df_30m['nwrqk_bear'].sum():,}\")\nelse:\n    print(\"  ❌ No data loaded\")\n\nprint(\"\\n\" + \"=\"*80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 7: Data Alignment and Preparation ===\n",
    "\n",
    "def prepare_backtest_data(df_30m, df_5m):\n",
    "    \"\"\"Align 30-minute indicators to 5-minute timeframe\"\"\"\n",
    "    print(\"=== Preparing Backtesting Data ===\")\n",
    "    \n",
    "    # Ensure both dataframes have datetime index\n",
    "    if not isinstance(df_5m.index, pd.DatetimeIndex) or not isinstance(df_30m.index, pd.DatetimeIndex):\n",
    "        print(\"❌ Error: Both dataframes must have datetime index\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Start with 5-minute data\n",
    "    df_aligned = df_5m.copy()\n",
    "    \n",
    "    # Align 30-minute indicators using forward fill\n",
    "    print(\"\\nAligning 30-minute indicators...\")\n",
    "    \n",
    "    # Select columns to align\n",
    "    cols_to_align = ['mlmi', 'mlmi_bull', 'mlmi_bear', 'nwrqk_bull', 'nwrqk_bear']\n",
    "    \n",
    "    for col in cols_to_align:\n",
    "        if col in df_30m.columns:\n",
    "            # Reindex and forward fill\n",
    "            df_aligned[f'{col}_30m'] = df_30m[col].reindex(df_aligned.index, method='ffill')\n",
    "            print(f\"  ✅ Aligned {col}\")\n",
    "    \n",
    "    # Add trading features\n",
    "    df_aligned['Returns'] = df_aligned['Close'].pct_change()\n",
    "    df_aligned['ATR_20'] = df_aligned['High'].subtract(df_aligned['Low']).rolling(20).mean()\n",
    "    \n",
    "    # Drop NaN values\n",
    "    df_aligned = df_aligned.dropna()\n",
    "    \n",
    "    print(f\"\\n✅ Data preparation complete!\")\n",
    "    print(f\"  • Total rows: {len(df_aligned):,}\")\n",
    "    print(f\"  • Date range: {df_aligned.index[0]} to {df_aligned.index[-1]}\")\n",
    "    \n",
    "    return df_aligned\n",
    "\n",
    "# Prepare backtesting data\n",
    "if not df_30m.empty and not df_5m.empty:\n",
    "    df_backtest = prepare_backtest_data(df_30m, df_5m)\n",
    "    print(\"\\n✅ Backtesting data ready!\")\n",
    "else:\n",
    "    print(\"❌ Missing required data for backtesting\")\n",
    "    df_backtest = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 8: Synergy Type 1 - MLMI → FVG → NWRQK ===\n",
    "\n",
    "@njit\n",
    "def detect_synergy_type1(mlmi_bull, mlmi_bear, fvg_bull, fvg_bear, \n",
    "                        nwrqk_bull, nwrqk_bear, n):\n",
    "    \"\"\"Detect Type 1 Synergy: MLMI → FVG → NWRQK\"\"\"\n",
    "    long_signals = np.zeros(n, dtype=np.bool_)\n",
    "    short_signals = np.zeros(n, dtype=np.bool_)\n",
    "    \n",
    "    # Window for synergy completion\n",
    "    window = 30  # bars to complete synergy\n",
    "    \n",
    "    for i in range(2, n-window):\n",
    "        # Check for MLMI signal\n",
    "        if mlmi_bull[i] and not mlmi_bull[i-1]:  # MLMI turns bullish\n",
    "            # Look for FVG within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if fvg_bull[j]:\n",
    "                    # Look for NWRQK confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if nwrqk_bull[k]:\n",
    "                            long_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "        \n",
    "        elif mlmi_bear[i] and not mlmi_bear[i-1]:  # MLMI turns bearish\n",
    "            # Look for FVG within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if fvg_bear[j]:\n",
    "                    # Look for NWRQK confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if nwrqk_bear[k]:\n",
    "                            short_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "    \n",
    "    return long_signals, short_signals\n",
    "\n",
    "class SynergyType1Strategy:\n",
    "    \"\"\"Strategy for Synergy Type 1: MLMI → FVG → NWRQK\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"Type 1: MLMI → FVG → NWRQK\"\n",
    "    \n",
    "    def generate_signals(self):\n",
    "        \"\"\"Generate entry and exit signals\"\"\"\n",
    "        print(f\"\\n🎯 Generating signals for {self.name}...\")\n",
    "        \n",
    "        # Extract arrays\n",
    "        mlmi_bull = self.data['mlmi_bull_30m'].fillna(False).values\n",
    "        mlmi_bear = self.data['mlmi_bear_30m'].fillna(False).values\n",
    "        fvg_bull = self.data['FVG_Bull_Active'].values\n",
    "        fvg_bear = self.data['FVG_Bear_Active'].values\n",
    "        nwrqk_bull = self.data['nwrqk_bull_30m'].fillna(False).values\n",
    "        nwrqk_bear = self.data['nwrqk_bear_30m'].fillna(False).values\n",
    "        \n",
    "        # Detect synergy signals\n",
    "        long_entries, short_entries = detect_synergy_type1(\n",
    "            mlmi_bull, mlmi_bear, fvg_bull, fvg_bear, \n",
    "            nwrqk_bull, nwrqk_bear, len(self.data)\n",
    "        )\n",
    "        \n",
    "        # Generate exit signals (simple ATR-based)\n",
    "        long_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        short_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        \n",
    "        print(f\"  • Long entries: {long_entries.sum():,}\")\n",
    "        print(f\"  • Short entries: {short_entries.sum():,}\")\n",
    "        \n",
    "        return {\n",
    "            'long_entries': pd.Series(long_entries, index=self.data.index),\n",
    "            'short_entries': pd.Series(short_entries, index=self.data.index),\n",
    "            'long_exits': pd.Series(long_exits, index=self.data.index),\n",
    "            'short_exits': pd.Series(short_exits, index=self.data.index)\n",
    "        }\n",
    "    \n",
    "    def backtest(self):\n",
    "        \"\"\"Run vectorbt backtest\"\"\"\n",
    "        signals = self.generate_signals()\n",
    "        \n",
    "        # Run backtest with vectorbt\n",
    "        try:\n",
    "            portfolio = vbt.Portfolio.from_signals(\n",
    "                close=self.data['Close'],\n",
    "                entries=signals['long_entries'] | signals['short_entries'],\n",
    "                exits=signals['long_exits'] | signals['short_exits'],\n",
    "                direction=np.where(signals['long_entries'], 1, \n",
    "                                 np.where(signals['short_entries'], -1, 0)),\n",
    "                size=100,\n",
    "                init_cash=100000,\n",
    "                fees=0.0001,\n",
    "                slippage=0.0001,\n",
    "                freq='5T'\n",
    "            )\n",
    "            \n",
    "            return portfolio\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Backtest error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Run Type 1 Synergy\n",
    "if not df_backtest.empty:\n",
    "    print(\"=\"*80)\n",
    "    print(\"📊 SYNERGY TYPE 1 - MLMI → FVG → NWRQK\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    strategy1 = SynergyType1Strategy(df_backtest)\n",
    "    portfolio1 = strategy1.backtest()\n",
    "    \n",
    "    if portfolio1:\n",
    "        print(f\"\\n📈 Results:\")\n",
    "        print(f\"  • Total Return: {portfolio1.total_return():.2%}\")\n",
    "        print(f\"  • Sharpe Ratio: {portfolio1.sharpe_ratio():.2f}\")\n",
    "        print(f\"  • Max Drawdown: {portfolio1.max_drawdown():.2%}\")\n",
    "        print(f\"  • Total Trades: {portfolio1.stats()['Total Trades']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 9: Synergy Type 2 - MLMI → NWRQK → FVG ===\n",
    "\n",
    "@njit\n",
    "def detect_synergy_type2(mlmi_bull, mlmi_bear, nwrqk_bull, nwrqk_bear,\n",
    "                        fvg_bull, fvg_bear, n):\n",
    "    \"\"\"Detect Type 2 Synergy: MLMI → NWRQK → FVG\"\"\"\n",
    "    long_signals = np.zeros(n, dtype=np.bool_)\n",
    "    short_signals = np.zeros(n, dtype=np.bool_)\n",
    "    \n",
    "    # Window for synergy completion\n",
    "    window = 30  # bars to complete synergy\n",
    "    \n",
    "    for i in range(2, n-window):\n",
    "        # Check for MLMI signal\n",
    "        if mlmi_bull[i] and not mlmi_bull[i-1]:  # MLMI turns bullish\n",
    "            # Look for NWRQK within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if nwrqk_bull[j]:\n",
    "                    # Look for FVG confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if fvg_bull[k]:\n",
    "                            long_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "        \n",
    "        elif mlmi_bear[i] and not mlmi_bear[i-1]:  # MLMI turns bearish\n",
    "            # Look for NWRQK within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if nwrqk_bear[j]:\n",
    "                    # Look for FVG confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if fvg_bear[k]:\n",
    "                            short_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "    \n",
    "    return long_signals, short_signals\n",
    "\n",
    "class SynergyType2Strategy:\n",
    "    \"\"\"Strategy for Synergy Type 2: MLMI → NWRQK → FVG\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"Type 2: MLMI → NWRQK → FVG\"\n",
    "    \n",
    "    def generate_signals(self):\n",
    "        \"\"\"Generate entry and exit signals\"\"\"\n",
    "        print(f\"\\n🎯 Generating signals for {self.name}...\")\n",
    "        \n",
    "        # Extract arrays\n",
    "        mlmi_bull = self.data['mlmi_bull_30m'].fillna(False).values\n",
    "        mlmi_bear = self.data['mlmi_bear_30m'].fillna(False).values\n",
    "        nwrqk_bull = self.data['nwrqk_bull_30m'].fillna(False).values\n",
    "        nwrqk_bear = self.data['nwrqk_bear_30m'].fillna(False).values\n",
    "        fvg_bull = self.data['FVG_Bull_Active'].values\n",
    "        fvg_bear = self.data['FVG_Bear_Active'].values\n",
    "        \n",
    "        # Detect synergy signals\n",
    "        long_entries, short_entries = detect_synergy_type2(\n",
    "            mlmi_bull, mlmi_bear, nwrqk_bull, nwrqk_bear,\n",
    "            fvg_bull, fvg_bear, len(self.data)\n",
    "        )\n",
    "        \n",
    "        # Generate exit signals\n",
    "        long_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        short_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        \n",
    "        print(f\"  • Long entries: {long_entries.sum():,}\")\n",
    "        print(f\"  • Short entries: {short_entries.sum():,}\")\n",
    "        \n",
    "        return {\n",
    "            'long_entries': pd.Series(long_entries, index=self.data.index),\n",
    "            'short_entries': pd.Series(short_entries, index=self.data.index),\n",
    "            'long_exits': pd.Series(long_exits, index=self.data.index),\n",
    "            'short_exits': pd.Series(short_exits, index=self.data.index)\n",
    "        }\n",
    "    \n",
    "    def backtest(self):\n",
    "        \"\"\"Run vectorbt backtest\"\"\"\n",
    "        signals = self.generate_signals()\n",
    "        \n",
    "        # Run backtest with vectorbt\n",
    "        try:\n",
    "            portfolio = vbt.Portfolio.from_signals(\n",
    "                close=self.data['Close'],\n",
    "                entries=signals['long_entries'] | signals['short_entries'],\n",
    "                exits=signals['long_exits'] | signals['short_exits'],\n",
    "                direction=np.where(signals['long_entries'], 1, \n",
    "                                 np.where(signals['short_entries'], -1, 0)),\n",
    "                size=100,\n",
    "                init_cash=100000,\n",
    "                fees=0.0001,\n",
    "                slippage=0.0001,\n",
    "                freq='5T'\n",
    "            )\n",
    "            \n",
    "            return portfolio\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Backtest error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Run Type 2 Synergy\n",
    "if not df_backtest.empty:\n",
    "    print(\"=\"*80)\n",
    "    print(\"📊 SYNERGY TYPE 2 - MLMI → NWRQK → FVG\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    strategy2 = SynergyType2Strategy(df_backtest)\n",
    "    portfolio2 = strategy2.backtest()\n",
    "    \n",
    "    if portfolio2:\n",
    "        print(f\"\\n📈 Results:\")\n",
    "        print(f\"  • Total Return: {portfolio2.total_return():.2%}\")\n",
    "        print(f\"  • Sharpe Ratio: {portfolio2.sharpe_ratio():.2f}\")\n",
    "        print(f\"  • Max Drawdown: {portfolio2.max_drawdown():.2%}\")\n",
    "        print(f\"  • Total Trades: {portfolio2.stats()['Total Trades']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 10: Synergy Type 3 - NWRQK → MLMI → FVG ===\n",
    "\n",
    "@njit\n",
    "def detect_synergy_type3(nwrqk_bull, nwrqk_bear, mlmi_bull, mlmi_bear,\n",
    "                        fvg_bull, fvg_bear, n):\n",
    "    \"\"\"Detect Type 3 Synergy: NWRQK → MLMI → FVG\"\"\"\n",
    "    long_signals = np.zeros(n, dtype=np.bool_)\n",
    "    short_signals = np.zeros(n, dtype=np.bool_)\n",
    "    \n",
    "    # Window for synergy completion\n",
    "    window = 30  # bars to complete synergy\n",
    "    \n",
    "    for i in range(2, n-window):\n",
    "        # Check for NWRQK signal\n",
    "        if nwrqk_bull[i]:  # NWRQK bullish change\n",
    "            # Look for MLMI confirmation within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if mlmi_bull[j]:\n",
    "                    # Look for FVG confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if fvg_bull[k]:\n",
    "                            long_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "        \n",
    "        elif nwrqk_bear[i]:  # NWRQK bearish change\n",
    "            # Look for MLMI confirmation within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if mlmi_bear[j]:\n",
    "                    # Look for FVG confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if fvg_bear[k]:\n",
    "                            short_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "    \n",
    "    return long_signals, short_signals\n",
    "\n",
    "class SynergyType3Strategy:\n",
    "    \"\"\"Strategy for Synergy Type 3: NWRQK → MLMI → FVG\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"Type 3: NWRQK → MLMI → FVG\"\n",
    "    \n",
    "    def generate_signals(self):\n",
    "        \"\"\"Generate entry and exit signals\"\"\"\n",
    "        print(f\"\\n🎯 Generating signals for {self.name}...\")\n",
    "        \n",
    "        # Extract arrays\n",
    "        nwrqk_bull = self.data['nwrqk_bull_30m'].fillna(False).values\n",
    "        nwrqk_bear = self.data['nwrqk_bear_30m'].fillna(False).values\n",
    "        mlmi_bull = self.data['mlmi_bull_30m'].fillna(False).values\n",
    "        mlmi_bear = self.data['mlmi_bear_30m'].fillna(False).values\n",
    "        fvg_bull = self.data['FVG_Bull_Active'].values\n",
    "        fvg_bear = self.data['FVG_Bear_Active'].values\n",
    "        \n",
    "        # Detect synergy signals\n",
    "        long_entries, short_entries = detect_synergy_type3(\n",
    "            nwrqk_bull, nwrqk_bear, mlmi_bull, mlmi_bear,\n",
    "            fvg_bull, fvg_bear, len(self.data)\n",
    "        )\n",
    "        \n",
    "        # Generate exit signals\n",
    "        long_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        short_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        \n",
    "        print(f\"  • Long entries: {long_entries.sum():,}\")\n",
    "        print(f\"  • Short entries: {short_entries.sum():,}\")\n",
    "        \n",
    "        return {\n",
    "            'long_entries': pd.Series(long_entries, index=self.data.index),\n",
    "            'short_entries': pd.Series(short_entries, index=self.data.index),\n",
    "            'long_exits': pd.Series(long_exits, index=self.data.index),\n",
    "            'short_exits': pd.Series(short_exits, index=self.data.index)\n",
    "        }\n",
    "    \n",
    "    def backtest(self):\n",
    "        \"\"\"Run vectorbt backtest\"\"\"\n",
    "        signals = self.generate_signals()\n",
    "        \n",
    "        # Run backtest with vectorbt\n",
    "        try:\n",
    "            portfolio = vbt.Portfolio.from_signals(\n",
    "                close=self.data['Close'],\n",
    "                entries=signals['long_entries'] | signals['short_entries'],\n",
    "                exits=signals['long_exits'] | signals['short_exits'],\n",
    "                direction=np.where(signals['long_entries'], 1, \n",
    "                                 np.where(signals['short_entries'], -1, 0)),\n",
    "                size=100,\n",
    "                init_cash=100000,\n",
    "                fees=0.0001,\n",
    "                slippage=0.0001,\n",
    "                freq='5T'\n",
    "            )\n",
    "            \n",
    "            return portfolio\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Backtest error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Run Type 3 Synergy\n",
    "if not df_backtest.empty:\n",
    "    print(\"=\"*80)\n",
    "    print(\"📊 SYNERGY TYPE 3 - NWRQK → MLMI → FVG\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    strategy3 = SynergyType3Strategy(df_backtest)\n",
    "    portfolio3 = strategy3.backtest()\n",
    "    \n",
    "    if portfolio3:\n",
    "        print(f\"\\n📈 Results:\")\n",
    "        print(f\"  • Total Return: {portfolio3.total_return():.2%}\")\n",
    "        print(f\"  • Sharpe Ratio: {portfolio3.sharpe_ratio():.2f}\")\n",
    "        print(f\"  • Max Drawdown: {portfolio3.max_drawdown():.2%}\")\n",
    "        print(f\"  • Total Trades: {portfolio3.stats()['Total Trades']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 11: Synergy Type 4 - NWRQK → FVG → MLMI ===\n",
    "\n",
    "@njit\n",
    "def detect_synergy_type4(nwrqk_bull, nwrqk_bear, fvg_bull, fvg_bear,\n",
    "                        mlmi_bull, mlmi_bear, n):\n",
    "    \"\"\"Detect Type 4 Synergy: NWRQK → FVG → MLMI\"\"\"\n",
    "    long_signals = np.zeros(n, dtype=np.bool_)\n",
    "    short_signals = np.zeros(n, dtype=np.bool_)\n",
    "    \n",
    "    # Window for synergy completion\n",
    "    window = 30  # bars to complete synergy\n",
    "    \n",
    "    for i in range(2, n-window):\n",
    "        # Check for NWRQK signal\n",
    "        if nwrqk_bull[i]:  # NWRQK bullish change\n",
    "            # Look for FVG within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if fvg_bull[j]:\n",
    "                    # Look for MLMI confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if mlmi_bull[k]:\n",
    "                            long_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "        \n",
    "        elif nwrqk_bear[i]:  # NWRQK bearish change\n",
    "            # Look for FVG within next bars\n",
    "            for j in range(i+1, min(i+window//2, n)):\n",
    "                if fvg_bear[j]:\n",
    "                    # Look for MLMI confirmation\n",
    "                    for k in range(j+1, min(i+window, n)):\n",
    "                        if mlmi_bear[k]:\n",
    "                            short_signals[k] = True\n",
    "                            break\n",
    "                    break\n",
    "    \n",
    "    return long_signals, short_signals\n",
    "\n",
    "class SynergyType4Strategy:\n",
    "    \"\"\"Strategy for Synergy Type 4: NWRQK → FVG → MLMI\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"Type 4: NWRQK → FVG → MLMI\"\n",
    "    \n",
    "    def generate_signals(self):\n",
    "        \"\"\"Generate entry and exit signals\"\"\"\n",
    "        print(f\"\\n🎯 Generating signals for {self.name}...\")\n",
    "        \n",
    "        # Extract arrays\n",
    "        nwrqk_bull = self.data['nwrqk_bull_30m'].fillna(False).values\n",
    "        nwrqk_bear = self.data['nwrqk_bear_30m'].fillna(False).values\n",
    "        fvg_bull = self.data['FVG_Bull_Active'].values\n",
    "        fvg_bear = self.data['FVG_Bear_Active'].values\n",
    "        mlmi_bull = self.data['mlmi_bull_30m'].fillna(False).values\n",
    "        mlmi_bear = self.data['mlmi_bear_30m'].fillna(False).values\n",
    "        \n",
    "        # Detect synergy signals\n",
    "        long_entries, short_entries = detect_synergy_type4(\n",
    "            nwrqk_bull, nwrqk_bear, fvg_bull, fvg_bear,\n",
    "            mlmi_bull, mlmi_bear, len(self.data)\n",
    "        )\n",
    "        \n",
    "        # Generate exit signals\n",
    "        long_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        short_exits = np.zeros(len(self.data), dtype=bool)\n",
    "        \n",
    "        print(f\"  • Long entries: {long_entries.sum():,}\")\n",
    "        print(f\"  • Short entries: {short_entries.sum():,}\")\n",
    "        \n",
    "        return {\n",
    "            'long_entries': pd.Series(long_entries, index=self.data.index),\n",
    "            'short_entries': pd.Series(short_entries, index=self.data.index),\n",
    "            'long_exits': pd.Series(long_exits, index=self.data.index),\n",
    "            'short_exits': pd.Series(short_exits, index=self.data.index)\n",
    "        }\n",
    "    \n",
    "    def backtest(self):\n",
    "        \"\"\"Run vectorbt backtest\"\"\"\n",
    "        signals = self.generate_signals()\n",
    "        \n",
    "        # Run backtest with vectorbt\n",
    "        try:\n",
    "            portfolio = vbt.Portfolio.from_signals(\n",
    "                close=self.data['Close'],\n",
    "                entries=signals['long_entries'] | signals['short_entries'],\n",
    "                exits=signals['long_exits'] | signals['short_exits'],\n",
    "                direction=np.where(signals['long_entries'], 1, \n",
    "                                 np.where(signals['short_entries'], -1, 0)),\n",
    "                size=100,\n",
    "                init_cash=100000,\n",
    "                fees=0.0001,\n",
    "                slippage=0.0001,\n",
    "                freq='5T'\n",
    "            )\n",
    "            \n",
    "            return portfolio\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Backtest error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Run Type 4 Synergy\n",
    "if not df_backtest.empty:\n",
    "    print(\"=\"*80)\n",
    "    print(\"📊 SYNERGY TYPE 4 - NWRQK → FVG → MLMI\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    strategy4 = SynergyType4Strategy(df_backtest)\n",
    "    portfolio4 = strategy4.backtest()\n",
    "    \n",
    "    if portfolio4:\n",
    "        print(f\"\\n📈 Results:\")\n",
    "        print(f\"  • Total Return: {portfolio4.total_return():.2%}\")\n",
    "        print(f\"  • Sharpe Ratio: {portfolio4.sharpe_ratio():.2f}\")\n",
    "        print(f\"  • Max Drawdown: {portfolio4.max_drawdown():.2%}\")\n",
    "        print(f\"  • Total Trades: {portfolio4.stats()['Total Trades']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 12: Monte Carlo Validation for Each Synergy ===\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "class MonteCarloValidator:\n",
    "    \"\"\"Monte Carlo validation for strategy performance\"\"\"\n",
    "    \n",
    "    def __init__(self, portfolio, strategy_name, n_simulations=1000):\n",
    "        self.portfolio = portfolio\n",
    "        self.strategy_name = strategy_name\n",
    "        self.n_simulations = n_simulations\n",
    "    \n",
    "    def run_validation(self):\n",
    "        \"\"\"Run Monte Carlo simulation\"\"\"\n",
    "        if not self.portfolio:\n",
    "            print(f\"❌ No portfolio available for {self.strategy_name}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\n🎲 Running Monte Carlo for {self.strategy_name}...\")\n",
    "        \n",
    "        # Get daily returns\n",
    "        returns = self.portfolio.returns()\n",
    "        \n",
    "        # Original metrics\n",
    "        original_return = self.portfolio.total_return()\n",
    "        original_sharpe = self.portfolio.sharpe_ratio()\n",
    "        \n",
    "        # Run simulations\n",
    "        sim_returns = []\n",
    "        sim_sharpes = []\n",
    "        \n",
    "        for _ in range(self.n_simulations):\n",
    "            # Bootstrap resample\n",
    "            sampled_returns = np.random.choice(returns, size=len(returns), replace=True)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            total_ret = np.prod(1 + sampled_returns) - 1\n",
    "            sharpe = np.mean(sampled_returns) / np.std(sampled_returns) * np.sqrt(252) if np.std(sampled_returns) > 0 else 0\n",
    "            \n",
    "            sim_returns.append(total_ret)\n",
    "            sim_sharpes.append(sharpe)\n",
    "        \n",
    "        # Calculate percentiles\n",
    "        return_percentile = stats.percentileofscore(sim_returns, original_return)\n",
    "        sharpe_percentile = stats.percentileofscore(sim_sharpes, original_sharpe)\n",
    "        \n",
    "        print(f\"  • Return Percentile: {return_percentile:.1f}%\")\n",
    "        print(f\"  • Sharpe Percentile: {sharpe_percentile:.1f}%\")\n",
    "        \n",
    "        return {\n",
    "            'original_return': original_return,\n",
    "            'original_sharpe': original_sharpe,\n",
    "            'return_percentile': return_percentile,\n",
    "            'sharpe_percentile': sharpe_percentile,\n",
    "            'sim_returns': sim_returns,\n",
    "            'sim_sharpes': sim_sharpes\n",
    "        }\n",
    "\n",
    "# Run Monte Carlo for each synergy\n",
    "print(\"=\"*80)\n",
    "print(\"🎲 MONTE CARLO VALIDATION FOR ALL SYNERGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Validate each synergy if portfolio exists\n",
    "synergy_results = {}\n",
    "\n",
    "if 'portfolio1' in locals() and portfolio1:\n",
    "    validator1 = MonteCarloValidator(portfolio1, \"Type 1: MLMI → FVG → NWRQK\")\n",
    "    synergy_results['Type 1'] = validator1.run_validation()\n",
    "\n",
    "if 'portfolio2' in locals() and portfolio2:\n",
    "    validator2 = MonteCarloValidator(portfolio2, \"Type 2: MLMI → NWRQK → FVG\")\n",
    "    synergy_results['Type 2'] = validator2.run_validation()\n",
    "\n",
    "if 'portfolio3' in locals() and portfolio3:\n",
    "    validator3 = MonteCarloValidator(portfolio3, \"Type 3: NWRQK → MLMI → FVG\")\n",
    "    synergy_results['Type 3'] = validator3.run_validation()\n",
    "\n",
    "if 'portfolio4' in locals() and portfolio4:\n",
    "    validator4 = MonteCarloValidator(portfolio4, \"Type 4: NWRQK → FVG → MLMI\")\n",
    "    synergy_results['Type 4'] = validator4.run_validation()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 MONTE CARLO SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for synergy_name, results in synergy_results.items():\n",
    "    if results:\n",
    "        avg_percentile = (results['return_percentile'] + results['sharpe_percentile']) / 2\n",
    "        print(f\"\\n{synergy_name}:\")\n",
    "        print(f\"  • Average Percentile: {avg_percentile:.1f}%\")\n",
    "        \n",
    "        if avg_percentile > 80:\n",
    "            print(\"  • Rating: ✅ EXCELLENT\")\n",
    "        elif avg_percentile > 60:\n",
    "            print(\"  • Rating: 👍 GOOD\")\n",
    "        else:\n",
    "            print(\"  • Rating: ⚠️ NEEDS IMPROVEMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 13: Final Summary and Recommendations ===\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"🏁 ALGOSPACE STRATEGY - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Collect all results\n",
    "all_portfolios = {\n",
    "    'Type 1: MLMI → FVG → NWRQK': portfolio1 if 'portfolio1' in locals() else None,\n",
    "    'Type 2: MLMI → NWRQK → FVG': portfolio2 if 'portfolio2' in locals() else None,\n",
    "    'Type 3: NWRQK → MLMI → FVG': portfolio3 if 'portfolio3' in locals() else None,\n",
    "    'Type 4: NWRQK → FVG → MLMI': portfolio4 if 'portfolio4' in locals() else None\n",
    "}\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\n📊 PERFORMANCE COMPARISON:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Synergy Type':<30} {'Return':>10} {'Sharpe':>10} {'Max DD':>10} {'Trades':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_return = -float('inf')\n",
    "best_sharpe = -float('inf')\n",
    "best_synergy_return = None\n",
    "best_synergy_sharpe = None\n",
    "\n",
    "for name, portfolio in all_portfolios.items():\n",
    "    if portfolio:\n",
    "        ret = portfolio.total_return()\n",
    "        sharpe = portfolio.sharpe_ratio()\n",
    "        dd = portfolio.max_drawdown()\n",
    "        trades = portfolio.stats()['Total Trades']\n",
    "        \n",
    "        print(f\"{name:<30} {ret:>10.2%} {sharpe:>10.2f} {dd:>10.2%} {trades:>10}\")\n",
    "        \n",
    "        if ret > best_return:\n",
    "            best_return = ret\n",
    "            best_synergy_return = name\n",
    "        \n",
    "        if sharpe > best_sharpe:\n",
    "            best_sharpe = sharpe\n",
    "            best_synergy_sharpe = name\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n🎯 RECOMMENDATIONS:\")\n",
    "if best_synergy_return:\n",
    "    print(f\"  • Best Return: {best_synergy_return} ({best_return:.2%})\")\n",
    "if best_synergy_sharpe:\n",
    "    print(f\"  • Best Risk-Adjusted: {best_synergy_sharpe} (Sharpe: {best_sharpe:.2f})\")\n",
    "\n",
    "print(\"\\n💡 STRATEGY INSIGHTS:\")\n",
    "print(\"  • Each synergy type captures different market dynamics\")\n",
    "print(\"  • Consider using multiple synergies with position sizing\")\n",
    "print(\"  • Monitor performance and adjust parameters as needed\")\n",
    "\n",
    "print(\"\\n✅ STRATEGY ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}