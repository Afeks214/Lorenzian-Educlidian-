"""
AGENT 3 MISSION: Liquidity Forcing Algorithm Exploitation Test Suite

This test suite exploits the execution engine's market impact prediction
and position sizing logic by creating extreme liquidity conditions that
force the system into predictable, suboptimal execution decisions.

ðŸŽ¯ ATTACK OBJECTIVE: Prove the system can be forced into bad execution decisions
through market manipulation and liquidity gaming.
"""

import pytest
import asyncio
import time
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, Any, List, Tuple
from unittest.mock import Mock, patch, AsyncMock
import logging

logger = logging.getLogger(__name__)

class LiquidityManipulator:
    """
    Sophisticated adversary that manipulates market liquidity to force
    the MARL system into predictable, exploitable execution patterns.
    
    ATTACK VECTOR: Create artificial liquidity conditions that trigger
    known execution algorithm responses and position sizing overrides.
    """
    
    def __init__(self):
        """Initialize the liquidity manipulation attack system."""
        # EXPLOIT: Known execution thresholds from documentation
        self.market_impact_thresholds = {
            "low": 0.01,      # 1% - Normal execution
            "medium": 0.025,  # 2.5% - Caution mode
            "high": 0.05,     # 5% - Position scaling required
            "extreme": 0.10   # 10% - Execution halt/rejection
        }
        
        # EXPLOIT: Known position sizing limits from source
        self.position_scaling_rules = {
            "confidence_multiplier_max": 1.5,    # From controller.py line 667
            "base_quantity": 1,                  # From controller.py line 665
            "max_participation_rate": 0.20,     # From README high confidence
            "min_participation_rate": 0.05      # From README low confidence
        }
        
        # EXPLOIT: Known risk limits from configuration examples
        self.known_risk_limits = {
            "max_order_size": 100000,        # From config example
            "max_notional": 5000000,         # From config example  
            "max_implementation_shortfall": 0.01,  # 1% max shortfall
            "max_execution_latency": 100     # 100ms max latency
        }
        
        # EXPLOIT: Known execution algorithms and their vulnerabilities
        self.algorithm_vulnerabilities = {
            "VWAP": {
                "duration_minutes": [60, 120],
                "participation_rate": [0.05, 0.10],
                "exploit": "Volume manipulation during VWAP window"
            },
            "TWAP": {
                "duration_minutes": [30, 120],
                "slice_duration": 5,
                "exploit": "Time-based slice prediction and front-running"
            },
            "ICEBERG": {
                "display_quantity": 0.1,
                "total_slices": 10,
                "exploit": "Order book manipulation to trigger slice reveals"
            }
        }
        
        self.manipulation_results = []
        logger.info("ðŸ•·ï¸ Liquidity manipulator initialized with execution logic knowledge")
    
    def create_thin_liquidity_scenario(self, symbol: str = "EURUSD") -> Dict[str, Any]:
        """
        EXPLOIT: Create artificially thin liquidity conditions.
        
        This simulates the adversary removing liquidity from the market
        just before the system attempts to execute, forcing bad execution.
        """
        # Normal market conditions (baseline)
        normal_conditions = {
            "bid_ask_spread": 0.0008,     # 0.8 pips
            "market_depth_bid": 1000000,  # 1M notional
            "market_depth_ask": 1000000,  # 1M notional
            "average_daily_volume": 50000000,  # 50M daily
            "liquidity_score": 0.85      # High liquidity
        }
        
        # ATTACK: Artificially thin liquidity
        manipulated_conditions = {
            "bid_ask_spread": 0.0050,     # 5.0 pips (6x wider)
            "market_depth_bid": 50000,    # 50k notional (20x less)
            "market_depth_ask": 50000,    # 50k notional (20x less)
            "average_daily_volume": 2000000,  # 2M daily (25x less)
            "liquidity_score": 0.15,     # Very low liquidity
            "manipulation_active": True,
            "liquidity_removed": 0.95    # 95% liquidity removed
        }
        
        logger.warning(f"ðŸŽ¯ LIQUIDITY MANIPULATION: Reduced liquidity by {manipulated_conditions['liquidity_removed']:.0%}")
        
        return {
            "symbol": symbol,
            "normal_conditions": normal_conditions,
            "manipulated_conditions": manipulated_conditions,
            "manipulation_factor": normal_conditions["liquidity_score"] / manipulated_conditions["liquidity_score"]
        }
    
    def predict_market_impact(self, order_size: float, liquidity_conditions: Dict[str, Any]) -> Dict[str, Any]:
        """
        EXPLOIT: Predict market impact using known calculation methods.
        
        From execution documentation: Impact increases non-linearly with
        order size relative to average daily volume and market depth.
        """
        conditions = liquidity_conditions["manipulated_conditions"]
        
        # EXPLOIT: Reverse-engineer market impact model
        # Market impact = f(order_size, daily_volume, market_depth, spread)
        participation_rate = order_size / conditions["average_daily_volume"]
        depth_ratio = order_size / conditions["market_depth_bid"]
        spread_penalty = conditions["bid_ask_spread"] / 0.0008  # Relative to normal spread
        
        # Non-linear impact calculation (typical institutional model)
        base_impact = np.sqrt(participation_rate) * 0.5  # Square root impact
        depth_impact = depth_ratio * 2.0 if depth_ratio > 0.1 else 0  # Depth penalty
        spread_impact = (spread_penalty - 1.0) * 0.3  # Spread penalty
        
        total_impact = base_impact + depth_impact + spread_impact
        
        # Classify impact level
        if total_impact >= self.market_impact_thresholds["extreme"]:
            impact_level = "extreme"
        elif total_impact >= self.market_impact_thresholds["high"]:
            impact_level = "high"
        elif total_impact >= self.market_impact_thresholds["medium"]:
            impact_level = "medium"
        else:
            impact_level = "low"
        
        return {
            "predicted_impact": total_impact,
            "impact_level": impact_level,
            "participation_rate": participation_rate,
            "depth_ratio": depth_ratio,
            "spread_penalty": spread_penalty,
            "components": {
                "base_impact": base_impact,
                "depth_impact": depth_impact, 
                "spread_impact": spread_impact
            }
        }
    
    def predict_position_scaling_response(self, original_order: Dict[str, Any],
                                        market_impact: Dict[str, Any]) -> Dict[str, Any]:
        """
        EXPLOIT: Predict how the system will scale down positions.
        
        From source analysis: Position sizing reduces based on market impact
        and confidence levels with predictable scaling factors.
        """
        original_size = original_order.get("quantity", 1.0)
        confidence = original_order.get("confidence", 0.75)
        impact_level = market_impact["impact_level"]
        
        # EXPLOIT: Known position scaling logic
        if impact_level == "extreme":
            # System will reject or severely scale down
            scaling_factor = 0.1  # 90% reduction
            will_execute = confidence > 0.95  # Only ultra-high confidence
            algorithm_override = "CANCEL"
        elif impact_level == "high":
            # System will scale down significantly
            scaling_factor = 0.3  # 70% reduction
            will_execute = confidence > 0.8
            algorithm_override = "MARKET_FRAGMENTED"
        elif impact_level == "medium":
            # System will scale down moderately
            scaling_factor = 0.6  # 40% reduction
            will_execute = confidence > 0.65
            algorithm_override = "TWAP_EXTENDED"
        else:
            # Normal execution
            scaling_factor = 1.0
            will_execute = True
            algorithm_override = None
        
        scaled_quantity = original_size * scaling_factor
        
        return {
            "will_execute": will_execute,
            "original_quantity": original_size,
            "scaled_quantity": scaled_quantity,
            "scaling_factor": scaling_factor,
            "algorithm_override": algorithm_override,
            "confidence_required": 0.95 if impact_level == "extreme" else 0.8 if impact_level == "high" else 0.65,
            "execution_method": self._predict_execution_method(impact_level, confidence)
        }
    
    def _predict_execution_method(self, impact_level: str, confidence: float) -> Dict[str, Any]:
        """EXPLOIT: Predict execution method based on impact and confidence."""
        if impact_level == "extreme":
            return {
                "algorithm": "CANCEL" if confidence < 0.95 else "MARKET_FRAGMENTED",
                "urgency": "immediate_or_cancel",
                "slicing": "minimal_size"
            }
        elif impact_level == "high":
            return {
                "algorithm": "TWAP",
                "duration_minutes": 240,  # Extended duration
                "participation_rate": 0.02,  # Very low participation
                "slicing": "micro_slices"
            }
        elif impact_level == "medium":
            return {
                "algorithm": "VWAP",
                "duration_minutes": 120,
                "participation_rate": 0.05,
                "slicing": "small_slices"
            }
        else:
            return {
                "algorithm": "TWAP",
                "duration_minutes": 30,
                "participation_rate": 0.10,
                "slicing": "normal"
            }
    
    async def execute_liquidity_forcing_attack(self, strategic_signal: Dict[str, Any]) -> Dict[str, Any]:
        """
        MAIN ATTACK: Execute liquidity forcing attack.
        
        ðŸŽ¯ ATTACK SEQUENCE:
        1. Detect incoming strategic signal (via front-running techniques)
        2. Remove liquidity from market to create thin conditions
        3. Force system into predictable scaling/cancellation behavior
        4. Exploit the forced execution pattern for profit
        """
        attack_start = time.perf_counter()
        
        # STEP 1: Create thin liquidity scenario
        liquidity_scenario = self.create_thin_liquidity_scenario()
        
        # STEP 2: Simulate the system's original order intent
        original_order = {
            "quantity": strategic_signal.get("target_position", 0.7),
            "confidence": strategic_signal.get("confidence", 0.85),
            "symbol": "EURUSD",
            "urgency": "normal"
        }
        
        # STEP 3: Predict market impact under thin liquidity
        market_impact = self.predict_market_impact(
            original_order["quantity"], 
            liquidity_scenario
        )
        
        # STEP 4: Predict system's position scaling response
        scaling_response = self.predict_position_scaling_response(
            original_order, 
            market_impact
        )
        
        # STEP 5: Execute exploitation strategy
        exploitation_result = await self._execute_exploitation_strategy(
            liquidity_scenario,
            original_order,
            scaling_response
        )
        
        attack_timing = {
            "total_attack_time": time.perf_counter() - attack_start,
            "liquidity_manipulation_window": 5.0,  # 5 seconds to manipulate
            "forced_response_delay": 10.0  # 10 seconds for system to respond
        }
        
        attack_result = {
            "attack_executed": True,
            "liquidity_scenario": liquidity_scenario,
            "original_order": original_order,
            "predicted_impact": market_impact,
            "predicted_scaling": scaling_response,
            "exploitation_result": exploitation_result,
            "timing": attack_timing,
            "vulnerability_exploited": "Market impact prediction and position scaling logic"
        }
        
        self.manipulation_results.append(attack_result)
        
        logger.critical(f"ðŸš¨ LIQUIDITY FORCING ATTACK EXECUTED! "
                       f"Impact: {market_impact['impact_level']} "
                       f"Scaling: {scaling_response['scaling_factor']:.2f} "
                       f"Will Execute: {scaling_response['will_execute']}")
        
        return attack_result
    
    async def _execute_exploitation_strategy(self, liquidity_scenario: Dict[str, Any],
                                           original_order: Dict[str, Any],
                                           scaling_response: Dict[str, Any]) -> Dict[str, Any]:
        """
        EXPLOIT: Execute the actual exploitation strategy.
        
        This is where the adversary profits from forcing the system
        into predictable behavior patterns.
        """
        # Simulate exploitation execution
        await asyncio.sleep(0.001)  # 1ms execution time
        
        exploitation_type = None
        estimated_profit = 0.0
        
        if not scaling_response["will_execute"]:
            # EXPLOIT: System cancellation
            exploitation_type = "CANCELLATION_ARBITRAGE"
            estimated_profit = 0.002  # 2 pips from cancellation pattern
            
        elif scaling_response["scaling_factor"] < 0.5:
            # EXPLOIT: Severe position scaling
            exploitation_type = "SCALING_ARBITRAGE"
            estimated_profit = 0.0015  # 1.5 pips from predictable scaling
            
        elif scaling_response["algorithm_override"]:
            # EXPLOIT: Algorithm override pattern
            exploitation_type = "ALGORITHM_GAMING"
            estimated_profit = 0.001  # 1 pip from gaming execution method
            
        else:
            exploitation_type = "IMPACT_ARBITRAGE"
            estimated_profit = 0.0005  # 0.5 pip from impact manipulation
        
        return {
            "exploitation_type": exploitation_type,
            "estimated_profit_pips": estimated_profit * 10000,  # Convert to pips
            "execution_method": "MARKET_MANIPULATION",
            "success_probability": 0.85,
            "detection_risk": "LOW - Appears as normal market conditions"
        }
    
    def analyze_execution_vulnerabilities(self, attack_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze vulnerabilities in execution logic."""
        if not attack_results:
            return {"vulnerability_count": 0}
        
        vulnerabilities = {
            "predictable_impact_calculation": 0,
            "exploitable_position_scaling": 0,
            "gameable_algorithm_selection": 0,
            "manipulatable_risk_overrides": 0
        }
        
        total_estimated_profit = 0.0
        
        for result in attack_results:
            # Count vulnerability types
            if result["predicted_impact"]["impact_level"] in ["high", "extreme"]:
                vulnerabilities["predictable_impact_calculation"] += 1
            
            if result["predicted_scaling"]["scaling_factor"] < 0.8:
                vulnerabilities["exploitable_position_scaling"] += 1
            
            if result["predicted_scaling"]["algorithm_override"]:
                vulnerabilities["gameable_algorithm_selection"] += 1
            
            if not result["predicted_scaling"]["will_execute"]:
                vulnerabilities["manipulatable_risk_overrides"] += 1
            
            total_estimated_profit += result["exploitation_result"]["estimated_profit_pips"]
        
        return {
            "total_attacks": len(attack_results),
            "vulnerabilities_found": vulnerabilities,
            "vulnerability_rate": sum(vulnerabilities.values()) / len(attack_results),
            "average_profit_per_attack": total_estimated_profit / len(attack_results),
            "total_estimated_profit_pips": total_estimated_profit,
            "critical_findings": [
                "Market impact calculation is predictable and exploitable",
                "Position scaling follows deterministic rules",
                "Algorithm selection can be gamed through liquidity manipulation",
                "Risk overrides are triggered by manipulatable market conditions"
            ]
        }


@pytest.mark.adversarial
class TestLiquidityForcingExploitation:
    """Test suite to demonstrate liquidity forcing vulnerabilities."""
    
    @pytest.fixture
    def manipulator(self):
        """Create liquidity manipulator."""
        return LiquidityManipulator()
    
    @pytest.fixture
    def strategic_signal_high_confidence(self):
        """High confidence strategic signal."""
        return {
            "target_position": 0.8,
            "confidence": 0.9,
            "pattern_type": "TYPE_1",
            "urgency": "high"
        }
    
    @pytest.fixture
    def strategic_signal_medium_confidence(self):
        """Medium confidence strategic signal."""
        return {
            "target_position": 0.6,
            "confidence": 0.7,
            "pattern_type": "TYPE_2", 
            "urgency": "medium"
        }
    
    def test_thin_liquidity_creation(self, manipulator):
        """Test creation of artificially thin liquidity conditions."""
        scenario = manipulator.create_thin_liquidity_scenario()
        
        assert "manipulated_conditions" in scenario
        assert "normal_conditions" in scenario
        assert scenario["manipulated_conditions"]["liquidity_removed"] > 0.9
        
        # Verify liquidity manipulation effectiveness
        normal_depth = scenario["normal_conditions"]["market_depth_bid"]
        thin_depth = scenario["manipulated_conditions"]["market_depth_bid"]
        liquidity_reduction = 1 - (thin_depth / normal_depth)
        
        assert liquidity_reduction > 0.9  # >90% liquidity removed
        
        logger.warning(f"ðŸŽ¯ Liquidity reduced by {liquidity_reduction:.1%}")
    
    def test_market_impact_prediction_accuracy(self, manipulator):
        """Test accuracy of market impact prediction."""
        scenario = manipulator.create_thin_liquidity_scenario()
        
        # Test different order sizes
        test_orders = [0.1, 0.5, 1.0, 2.0, 5.0]  # Various position sizes
        
        for order_size in test_orders:
            impact = manipulator.predict_market_impact(order_size, scenario)
            
            assert "predicted_impact" in impact
            assert "impact_level" in impact
            assert impact["predicted_impact"] >= 0
            
            # Larger orders should have higher impact
            if order_size >= 2.0:
                assert impact["impact_level"] in ["high", "extreme"]
                logger.warning(f"ðŸŽ¯ Order size {order_size}: {impact['impact_level']} impact "
                              f"({impact['predicted_impact']:.3f})")
    
    def test_position_scaling_prediction(self, manipulator, strategic_signal_high_confidence):
        """Test prediction of position scaling responses."""
        scenario = manipulator.create_thin_liquidity_scenario()
        
        # Test with high impact scenario
        market_impact = manipulator.predict_market_impact(2.0, scenario)  # Large order
        scaling_response = manipulator.predict_position_scaling_response(
            strategic_signal_high_confidence, market_impact
        )
        
        assert "scaling_factor" in scaling_response
        assert "will_execute" in scaling_response
        assert 0 <= scaling_response["scaling_factor"] <= 1.0
        
        # High impact should trigger scaling
        if market_impact["impact_level"] in ["high", "extreme"]:
            assert scaling_response["scaling_factor"] < 0.8
            logger.warning(f"ðŸŽ¯ Position scaled by {1-scaling_response['scaling_factor']:.1%} "
                          f"due to {market_impact['impact_level']} impact")
    
    @pytest.mark.asyncio
    async def test_complete_liquidity_forcing_attack(self, manipulator, strategic_signal_high_confidence):
        """Test complete liquidity forcing attack."""
        attack_result = await manipulator.execute_liquidity_forcing_attack(strategic_signal_high_confidence)
        
        assert attack_result["attack_executed"] is True
        assert "liquidity_scenario" in attack_result
        assert "predicted_impact" in attack_result
        assert "predicted_scaling" in attack_result
        assert "exploitation_result" in attack_result
        
        # Verify attack effectiveness
        impact_level = attack_result["predicted_impact"]["impact_level"]
        scaling_factor = attack_result["predicted_scaling"]["scaling_factor"]
        exploitation_profit = attack_result["exploitation_result"]["estimated_profit_pips"]
        
        # VULNERABILITY: System can be forced into suboptimal execution
        if impact_level in ["high", "extreme"]:
            assert scaling_factor < 0.8 or not attack_result["predicted_scaling"]["will_execute"]
            assert exploitation_profit > 0.5  # >0.5 pip profit
            
            logger.critical(f"ðŸš¨ LIQUIDITY FORCING SUCCESS! "
                           f"Impact: {impact_level}, "
                           f"Scaling: {scaling_factor:.2f}, "
                           f"Profit: {exploitation_profit:.1f} pips")
            
            # FAIL: System is vulnerable to liquidity manipulation
            assert False, f"EXECUTION VULNERABILITY: Forced {impact_level} impact with {exploitation_profit:.1f} pips profit"
    
    def test_algorithm_override_exploitation(self, manipulator, strategic_signal_medium_confidence):
        """Test exploitation of algorithm override logic."""
        scenario = manipulator.create_thin_liquidity_scenario()
        
        # Create extreme impact scenario
        extreme_order = {"quantity": 5.0, "confidence": 0.7}  # Large order, medium confidence
        market_impact = manipulator.predict_market_impact(5.0, scenario)
        scaling_response = manipulator.predict_position_scaling_response(extreme_order, market_impact)
        
        # VULNERABILITY: Algorithm overrides are predictable
        if market_impact["impact_level"] == "extreme":
            assert scaling_response["algorithm_override"] in ["CANCEL", "MARKET_FRAGMENTED"]
            assert scaling_response["confidence_required"] >= 0.95
            
            logger.warning(f"ðŸŽ¯ Algorithm override triggered: {scaling_response['algorithm_override']} "
                          f"requires {scaling_response['confidence_required']:.2f} confidence")
    
    @pytest.mark.stress  
    async def test_systematic_liquidity_manipulation(self, manipulator):
        """Test systematic manipulation across multiple scenarios."""
        test_scenarios = [
            {"target_position": 0.5, "confidence": 0.75},
            {"target_position": 1.0, "confidence": 0.85},
            {"target_position": 1.5, "confidence": 0.9},
            {"target_position": 2.0, "confidence": 0.8},
            {"target_position": 3.0, "confidence": 0.95}
        ]
        
        for scenario in test_scenarios:
            attack_result = await manipulator.execute_liquidity_forcing_attack(scenario)
            
            # Record results for analysis
            assert attack_result["attack_executed"] is True
        
        # Analyze systematic vulnerabilities
        vulnerability_analysis = manipulator.analyze_execution_vulnerabilities(
            manipulator.manipulation_results
        )
        
        vulnerability_rate = vulnerability_analysis["vulnerability_rate"]
        total_profit = vulnerability_analysis["total_estimated_profit_pips"]
        
        logger.critical(f"ðŸš¨ SYSTEMATIC MANIPULATION RESULTS:")
        logger.critical(f"   Vulnerability Rate: {vulnerability_rate:.2f} per attack")
        logger.critical(f"   Total Profit: {total_profit:.1f} pips")
        logger.critical(f"   Average Profit: {vulnerability_analysis['average_profit_per_attack']:.2f} pips/attack")
        
        for finding in vulnerability_analysis["critical_findings"]:
            logger.critical(f"   - {finding}")
        
        # CRITICAL: High vulnerability rate indicates systematic weakness
        assert vulnerability_rate < 0.5, f"CRITICAL: {vulnerability_rate:.1f} vulnerabilities per attack"
        assert total_profit < 50.0, f"CRITICAL: {total_profit:.1f} pips total profit opportunity"
    
    def test_risk_override_manipulation(self, manipulator):
        """Test manipulation of risk override mechanisms."""
        scenario = manipulator.create_thin_liquidity_scenario()
        
        # Test orders that should trigger risk overrides
        risky_orders = [
            {"quantity": 10.0, "confidence": 0.6},   # Massive order, low confidence
            {"quantity": 5.0, "confidence": 0.8},    # Large order, medium confidence
            {"quantity": 3.0, "confidence": 0.94}    # Medium order, just below override threshold
        ]
        
        risk_overrides_triggered = 0
        
        for order in risky_orders:
            market_impact = manipulator.predict_market_impact(order["quantity"], scenario)
            scaling_response = manipulator.predict_position_scaling_response(order, market_impact)
            
            if not scaling_response["will_execute"] or scaling_response["scaling_factor"] < 0.2:
                risk_overrides_triggered += 1
                
                logger.warning(f"ðŸŽ¯ Risk override triggered for order {order['quantity']} "
                              f"with confidence {order['confidence']:.2f}")
        
        # VULNERABILITY: Risk overrides are predictable and manipulatable
        override_rate = risk_overrides_triggered / len(risky_orders)
        assert override_rate > 0.5, f"Risk override rate: {override_rate:.1%}"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])